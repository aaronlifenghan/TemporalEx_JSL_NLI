{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59278,"status":"ok","timestamp":1724673613271,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":-480},"id":"szSS9a0i0E2C","outputId":"87012e41-ac9e-4048-de8f-6cd0cabb9e7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"opa9uIyHzHSf"},"source":["实验\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"elapsed":15115,"status":"error","timestamp":1720558969801,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":-60},"id":"ROluvIpACiR5","outputId":"92a77955-2f8d-4fb8-a859-99ca0170e033"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-e43114604f88>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mElementTree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizerFast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Initialize spacy and BERT tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from .utils import (\n\u001b[1;32m     28\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# not required, check version only if installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"can't find {pkg} in {deps.keys()}, check dependency_versions_table.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/versions.py\u001b[0m in \u001b[0;36mrequire_version_core\u001b[0;34m(requirement)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;34m\"\"\"require_version wrapper which emits a core-specific hint on failure\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0mhint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Try: `pip install transformers -U` or `pip install -e '.[dev]'` if you're working with git main\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequirement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/versions.py\u001b[0m in \u001b[0;36mrequire_version\u001b[0;34m(requirement, hint)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwant_ver\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwant_ver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwanted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0m_compare_versions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwant_ver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequirement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/versions.py\u001b[0m in \u001b[0;36m_compare_versions\u001b[0;34m(op, got_ver, want_ver, requirement, pkg, hint)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;34mf\" reinstalling {pkg}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         )\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgot_ver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwant_ver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         raise ImportError(\n\u001b[1;32m     45\u001b[0m             \u001b[0;34mf\"{requirement} is required for a normal functioning of this module, but found {pkg}=={got_ver}.{hint}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os\n","import xml.etree.ElementTree as ET\n","import spacy\n","from transformers import BertTokenizerFast\n","\n","# Initialize spacy and BERT tokenizer\n","nlp = spacy.load(\"en_core_web_sm\")\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","\n","# Function to read and parse XML files\n","def parse_xml_files(directory):\n","    data = []\n","    for filename in os.listdir(directory):\n","        if filename.endswith(\".xml\"):\n","            try:\n","                tree = ET.parse(os.path.join(directory, filename))\n","                root = tree.getroot()\n","                text_content = root.find(\"TEXT\").text\n","                data.append((root, text_content))\n","            except ET.ParseError:\n","                print(f\"Error parsing {filename}, skipping...\")\n","    return data\n","\n","# Function to extract EVENT and TIMEX3 entities\n","def extract_entities(xml_data):\n","    data = []\n","    for entry, text in xml_data:\n","        events = []\n","        timex3s = []\n","        tlinks = []\n","\n","        for tag in entry.find(\"TAGS\"):\n","            if tag.tag == \"EVENT\" and tag.attrib[\"type\"] == \"TREATMENT\":\n","                events.append({\n","                    \"id\": tag.attrib[\"id\"],\n","                    \"text\": tag.attrib[\"text\"],\n","                    \"start\": int(tag.attrib[\"start\"]),\n","                    \"end\": int(tag.attrib[\"end\"]),\n","                    \"modality\": tag.attrib[\"modality\"],\n","                    \"polarity\": tag.attrib[\"polarity\"]\n","                })\n","            elif tag.tag == \"TIMEX3\" and tag.attrib[\"type\"] == \"DATE\":\n","                timex3s.append({\n","                    \"id\": tag.attrib[\"id\"],\n","                    \"text\": tag.attrib[\"text\"],\n","                    \"start\": int(tag.attrib[\"start\"]),\n","                    \"end\": int(tag.attrib[\"end\"]),\n","                    \"val\": tag.attrib[\"val\"]\n","                })\n","            elif tag.tag == \"TLINK\":\n","                tlinks.append({\n","                    \"fromID\": tag.attrib[\"fromID\"],\n","                    \"toID\": tag.attrib[\"toID\"],\n","                    \"type\": tag.attrib[\"type\"]\n","                })\n","\n","        data.append((events, timex3s, tlinks, text))\n","    return data\n","\n","# Function to link treatments with dates and annotate all time expressions\n","def link_treatments_with_dates(treatments, timex3s, tlinks, text):\n","    linked_data = {}\n","    for treatment in treatments:\n","        treatment_id = treatment[\"id\"]\n","        if treatment_id not in linked_data:\n","            linked_data[treatment_id] = {\n","                \"treatment\": treatment,\n","                \"dates\": [],\n","                \"text\": text,\n","                \"bio_time\": [\"O\"] * len(text),\n","                \"bio_treatment\": [\"O\"] * len(text),\n","                \"bio_tlink\": [\"O\"] * len(text)\n","            }\n","\n","        # Annotate all time expressions\n","        for timex in timex3s:\n","            bio_label = \"B-DATE\"\n","            linked_data[treatment_id][\"bio_time\"][timex[\"start\"]] = bio_label\n","            for i in range(timex[\"start\"] + 1, timex[\"end\"]):\n","                linked_data[treatment_id][\"bio_time\"][i] = \"I-DATE\"\n","\n","        # Annotate linked dates with TLINK types\n","        for tlink in tlinks:\n","            if tlink[\"fromID\"] == treatment_id or tlink[\"toID\"] == treatment_id:\n","                date_id = tlink[\"toID\"] if tlink[\"fromID\"] == treatment_id else tlink[\"fromID\"]\n","                date = next((t for t in timex3s if t[\"id\"] == date_id), None)\n","                if date:\n","                    linked_data[treatment_id][\"dates\"].append({\n","                        \"date\": date,\n","                        \"tlink_type\": tlink[\"type\"]\n","                    })\n","                    bio_label = f\"B-{tlink['type']}\"\n","                    linked_data[treatment_id][\"bio_tlink\"][date[\"start\"]] = bio_label\n","                    for i in range(date[\"start\"] + 1, date[\"end\"]):\n","                        linked_data[treatment_id][\"bio_tlink\"][i] = f\"I-{tlink['type']}\"\n","\n","        # Annotate treatments\n","        bio_label_treatment = \"B-TREATMENT\"\n","        linked_data[treatment_id][\"bio_treatment\"][treatment[\"start\"]] = bio_label_treatment\n","        for i in range(treatment[\"start\"] + 1, treatment[\"end\"]):\n","            linked_data[treatment_id][\"bio_treatment\"][i] = \"I-TREATMENT\"\n","\n","    return linked_data.values()\n","\n","# Function to align BIO annotations with tokenized text\n","def align_bio_with_tokens(text, bio_annotations, tokenizer):\n","    tokens = tokenizer.tokenize(text)\n","    token_offsets = tokenizer(text, return_offsets_mapping=True)[\"offset_mapping\"]\n","    # print(\"Token Offsets and Corresponding Tokens:\")\n","    # for token, (token_start, token_end) in zip(tokens, token_offsets):\n","    #     print(f\"Token: {token}, Start: {token_start}, End: {token_end}\")\n","    aligned_bio = []\n","    prev_tag = \"O\"\n","    for token_start, token_end in token_offsets:\n","        if token_start == token_end:\n","            continue\n","        if token_start >= len(bio_annotations):\n","            aligned_bio.append(\"O\")\n","            # print(f\"Token start {token_start} exceeds BIO annotations length {len(bio_annotations)}, appending 'O'\")\n","            continue\n","\n","        bio_tag = bio_annotations[token_start]\n","        if bio_tag.startswith(\"I-\") and prev_tag == \"O\":\n","            bio_tag = \"B-\" + bio_tag[2:]\n","        aligned_bio.append(bio_tag)\n","        prev_tag = bio_tag\n","    # print(aligned_bio)\n","    # Debugging: Print tokens and corresponding BIO tags that are not \"O\"\n","    # for token, bio_tag in zip(tokens, aligned_bio):\n","    #     if bio_tag != \"O\":\n","    #         print(f\"Token: {token}, BIO Tag: {bio_tag}\")\n","\n","    return tokens, aligned_bio\n","\n","# Function to chunk annotations around target sentences\n","def chunk_annotations(text, bio_time, bio_treatment, bio_tlink, tokenizer, window_size):\n","    # Tokenize text into sentences\n","    doc = nlp(text)\n","    sentences = list(doc.sents)\n","\n","    # Find sentence boundaries\n","    sentence_boundaries = [(sent.start_char, sent.end_char) for sent in sentences]\n","\n","    # Identify sentences containing target entities\n","    target_indices = []\n","    for i, (start, end) in enumerate(sentence_boundaries):\n","        if (any(tag.startswith(\"B-\") or tag.startswith(\"I-\") for tag in bio_time[start:end]) or\n","                any(tag.startswith(\"B-\") or tag.startswith(\"I-\") for tag in bio_treatment[start:end]) or\n","                    any(tag.startswith(\"B-\") or tag.startswith(\"I-\") for tag in bio_tlink[start:end])):\n","            target_indices.append(i)\n","\n","    # Extract sentences around target indices based on window size\n","    selected_indices = set()\n","    for idx in target_indices:\n","        start_idx = max(0, idx - window_size)\n","        end_idx = min(len(sentences), idx + window_size + 1)\n","        selected_indices.update(range(start_idx, end_idx))\n","\n","    # Combine selected sentences and update BIO annotations\n","    selected_indices = sorted(selected_indices)\n","    selected_text = \" \".join([sentences[i].text for i in selected_indices])\n","\n","    selected_bio_time = []\n","    selected_bio_treatment = []\n","    selected_bio_tlink = []\n","\n","    for idx in selected_indices:\n","        start, end = sentence_boundaries[idx]\n","        selected_bio_time.extend(bio_time[start:end])\n","        selected_bio_treatment.extend(bio_treatment[start:end])\n","        selected_bio_tlink.extend(bio_tlink[start:end])\n","\n","    # Debugging: Print selected sentences and BIO annotations\n","    # print(\"Selected Sentences:\\n\", selected_text)\n","    # print(\"Selected BIO Time (non-O):\")\n","    # for i, tag in enumerate(selected_bio_time):\n","    #     if tag != \"O\":\n","    #         print(f\"Token: {selected_text[i]}, BIO Tag: {tag}\")\n","\n","    # print(\"Selected BIO Treatment (non-O):\")\n","    # for i, tag in enumerate(selected_bio_treatment):\n","    #     if tag != \"O\":\n","    #         print(f\"Token: {selected_text[i]}, BIO Tag: {tag}\")\n","\n","    # print(\"Selected BIO TLINK (non-O):\")\n","    # for i, tag in enumerate(selected_bio_tlink):\n","    #     if tag != \"O\":\n","    #         print(f\"Token: {selected_text[i]}, BIO Tag: {tag}\")\n","\n","    # Align new selected text with BERT tokens\n","\n","    tokens, aligned_bio_time = align_bio_with_tokens(selected_text, selected_bio_time, tokenizer)\n","    _, aligned_bio_treatment = align_bio_with_tokens(selected_text, selected_bio_treatment, tokenizer)\n","    _, aligned_bio_tlink = align_bio_with_tokens(selected_text, selected_bio_tlink, tokenizer)\n","\n","    return selected_text, tokens, aligned_bio_time, aligned_bio_treatment, aligned_bio_tlink\n","\n","\n","# Main processing\n","xml_dir = \"/content/drive/MyDrive/UOM_year3/3rd_year_project/2012_Temporal_Relations_Challenge/2012-07-06.release-fix\"\n","xml_data = parse_xml_files(xml_dir)\n","extracted_data = extract_entities(xml_data)\n","temp = extracted_data[0:1]\n","# print(temp)\n","linked_treatments = []\n","for events, timex3s, tlinks, text in temp:\n","    linked_treatments.extend(link_treatments_with_dates(events, timex3s, tlinks, text))\n","print(\"/////////\")\n","print(linked_treatments)\n","# Align BIO annotations with BERT tokens for each entry\n","window_size = 0\n","processed_data = []\n","for entry in linked_treatments:\n","    text = entry[\"text\"]\n","    bio_time = entry[\"bio_time\"]\n","    bio_treatment = entry[\"bio_treatment\"]\n","    bio_tlink = entry[\"bio_tlink\"]\n","\n","    try:\n","        selected_text, tokens, aligned_bio_time, aligned_bio_treatment, aligned_bio_tlink = chunk_annotations(\n","            text, bio_time, bio_treatment, bio_tlink, tokenizer, window_size\n","        )\n","\n","        processed_data.append({\n","            \"selected_text\": selected_text,\n","            \"tokens\": tokens,\n","            \"aligned_bio_time\": aligned_bio_time,\n","            \"aligned_bio_treatment\": aligned_bio_treatment,\n","            \"aligned_bio_tlink\": aligned_bio_tlink\n","        })\n","    except Exception as e:\n","        print(f\"Error processing entry with text: {text[:50]}... Error: {e}\")\n","\n","# Example output\n","for entry in processed_data[:1]:  # printing only the first entry for brevity\n","    print(\"Selected Text:\", entry[\"selected_text\"])\n","    print(\"Tokens:\", entry[\"tokens\"])\n","    print(len(entry[\"tokens\"]))\n","    print(\"Aligned BIO Time:\", entry[\"aligned_bio_time\"])\n","    print(len(entry[\"aligned_bio_time\"]))\n","    print(\"Aligned BIO Treatment:\", entry[\"aligned_bio_treatment\"])\n","    print(len(entry[\"aligned_bio_treatment\"]))\n","    print(\"Aligned BIO TLINK:\", entry[\"aligned_bio_tlink\"])\n","    print(len(entry[\"aligned_bio_tlink\"]))\n","    print(\"\\n\")\n","\n","    # Collect non-O entities for BIO time annotations\n","    bio_time_entities = []\n","    current_entity = []\n","    current_label = None\n","    for token, bio_tag in zip(entry[\"tokens\"], entry[\"aligned_bio_time\"]):\n","        if bio_tag.startswith(\"B-\"):\n","            if current_entity:\n","                bio_time_entities.append((current_label, current_entity))\n","                current_entity = []\n","            current_label = bio_tag[2:]\n","            current_entity.append(token)\n","        elif bio_tag.startswith(\"I-\") and current_label == bio_tag[2:]:\n","            current_entity.append(token)\n","        else:\n","            if current_entity:\n","                bio_time_entities.append((current_label, current_entity))\n","                current_entity = []\n","            current_label = None\n","\n","    if current_entity:\n","        bio_time_entities.append((current_label, current_entity))\n","\n","    # Collect non-O entities for BIO treatment annotations\n","    bio_treatment_entities = []\n","    current_entity = []\n","    current_label = None\n","    for token, bio_tag in zip(entry[\"tokens\"], entry[\"aligned_bio_treatment\"]):\n","        if bio_tag.startswith(\"B-\"):\n","            if current_entity:\n","                bio_treatment_entities.append((current_label, current_entity))\n","                current_entity = []\n","            current_label = bio_tag[2:]\n","            current_entity.append(token)\n","        elif bio_tag.startswith(\"I-\") and current_label == bio_tag[2:]:\n","            current_entity.append(token)\n","        else:\n","            if current_entity:\n","                bio_treatment_entities.append((current_label, current_entity))\n","                current_entity = []\n","            current_label = None\n","\n","    if current_entity:\n","        bio_treatment_entities.append((current_label, current_entity))\n","\n","    # Collect non-O entities for BIO tlink annotations\n","    bio_tlink_entities = []\n","    current_entity = []\n","    current_label = None\n","    for token, bio_tag in zip(entry[\"tokens\"], entry[\"aligned_bio_tlink\"]):\n","        if bio_tag.startswith(\"B-\"):\n","            if current_entity:\n","                bio_tlink_entities.append((current_label, current_entity))\n","                current_entity = []\n","            current_label = bio_tag[2:]\n","            current_entity.append(token)\n","        elif bio_tag.startswith(\"I-\") and current_label == bio_tag[2:]:\n","            current_entity.append(token)\n","        else:\n","            if current_entity:\n","                bio_tlink_entities.append((current_label, current_entity))\n","                current_entity = []\n","            current_label = None\n","\n","    if current_entity:\n","        bio_tlink_entities.append((current_label, current_entity))\n","\n","    print(\"BIO Time Entities:\")\n","    for label, tokens in bio_time_entities:\n","        print(f\"Entity: {' '.join(tokens)}, Label: {label}\")\n","\n","    print(\"\\nBIO Treatment Entities:\")\n","    for label, tokens in bio_treatment_entities:\n","        print(f\"Entity: {' '.join(tokens)}, Label: {label}\")\n","\n","    print(\"\\nBIO TLINK Entities:\")\n","    for label, tokens in bio_tlink_entities:\n","        print(f\"Entity: {' '.join(tokens)}, Label: {label}\")\n"]},{"cell_type":"markdown","metadata":{"id":"J3YRWdB4zLTz"},"source":["试验后运行"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":301,"referenced_widgets":["118d6aae7fc346e4a1736d6bc249b930","b757b360627e4389a90e1b485bc61ac9","cee12ab57f7041659be816f8cf2b8e71","a261776c40f94be9b1d50d87fbb67b79","706f9274d5d24e739877f4122f1423f8","2a68b0a635c44624a959067d449ef1cb","7b72cb404bb2475b904ee029efb884c6","ae0efe1a3494495a82d6aa320055477e","dc563fd586df403aa1bbdbe2fac8e8d0","e55aa611423542929e96ea6e3373fcbf","b6e09dce0e0b47679a49c0fb8d9fa4f2","c48a79e3219a4b7aaee5f4779d5cdd20","873efed9f48f44059687ddab8c7b68b5","28a27ea38f9246d59f6fa1ad6427df52","9a6d19178c1443c495c39c5552e044bd","218747659d7140b3ae0b79a4c33d1913","70e818db46f54cdcabc7cee7fb800ff3","20af1155376d463286f4c80fdc9fb3e6","b7baa4fa724d458bb5540c8382fa9b0b","54d27c01a6df4ee3812fd208cb798f76","c825b8faec6e4aca84d2f9db9df80218","d29bddf100b34e5d84af777da6fc3882","30df7fef73944e8eb28b199cb56408f0","9485bc7869c5464089490638de80491c","139d2e3407f74834938e9d659d33da9a","be53917e12b0402590e1940e74a11954","d5c005ab5a02485297ae07238ac1c09a","550c9110efec4803b69d0b0d720e731a","b2f6565da1ac4e4bb86d6ce82ac4ff4d","25922cfb99f04a5e970fc93e0f0b2f09","c190b1d6ebb04dc5ad9abc5a3bcc65d9","0553068fd8734f73819165a22972ccab","2b593fb72c4642d581205bb8a88fafdc","0422c7dbdf534ba7ba31dc4357df290e","e36c4a9d1f544948a6f76278ac8e05e5","834125b4fa594c479551a2b1d6845383","d96ceea82ea34d9394aa4f9d58c46651","f80fcb022d92454fb865138d67b3c79b","901e1b03f85a4fc4b73a9476ab22a1a5","6261eea7475c4b41add98bd634504663","9774ee37643f4ba18eb4ba942c9d8137","c46d75636073439f813c9f491983db98","7013f6bfc731463e8b3ba0d3f6d46bf2","c2d79344680e4c9ba87e3ce7d54b1469"]},"executionInfo":{"elapsed":296027,"status":"ok","timestamp":1724673938530,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":-480},"id":"-Oenjr2t8Coh","outputId":"62024036-40d9-4427-ff2d-4ba974b4bb9a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"118d6aae7fc346e4a1736d6bc249b930"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c48a79e3219a4b7aaee5f4779d5cdd20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30df7fef73944e8eb28b199cb56408f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0422c7dbdf534ba7ba31dc4357df290e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Error parsing 807.xml, skipping...\n","Error parsing 422.xml, skipping...\n"]},{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n"]}],"source":["import os\n","import xml.etree.ElementTree as ET\n","import spacy\n","from transformers import BertTokenizerFast\n","\n","# Initialize spacy and BERT tokenizer\n","nlp = spacy.load(\"en_core_web_sm\")\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","\n","# Function to read and parse XML files\n","def parse_xml_files(directory):\n","    data = []\n","    for filename in os.listdir(directory):\n","        if filename.endswith(\".xml\"):\n","            try:\n","                tree = ET.parse(os.path.join(directory, filename))\n","                root = tree.getroot()\n","                text_content = root.find(\"TEXT\").text\n","                data.append((root, text_content))\n","            except ET.ParseError:\n","                print(f\"Error parsing {filename}, skipping...\")\n","    return data\n","\n","# Function to extract EVENT and TIMEX3 entities\n","def extract_entities(xml_data):\n","    data = []\n","    for entry, text in xml_data:\n","        events = []\n","        timex3s = []\n","        tlinks = []\n","\n","        for tag in entry.find(\"TAGS\"):\n","            if tag.tag == \"EVENT\" and tag.attrib[\"type\"] == \"TREATMENT\":\n","                events.append({\n","                    \"id\": tag.attrib[\"id\"],\n","                    \"text\": tag.attrib[\"text\"],\n","                    \"start\": int(tag.attrib[\"start\"]),\n","                    \"end\": int(tag.attrib[\"end\"]),\n","                    \"modality\": tag.attrib[\"modality\"],\n","                    \"polarity\": tag.attrib[\"polarity\"]\n","                })\n","            elif tag.tag == \"TIMEX3\" and tag.attrib[\"type\"] == \"DATE\":\n","                timex3s.append({\n","                    \"id\": tag.attrib[\"id\"],\n","                    \"text\": tag.attrib[\"text\"],\n","                    \"start\": int(tag.attrib[\"start\"]),\n","                    \"end\": int(tag.attrib[\"end\"]),\n","                    \"val\": tag.attrib[\"val\"]\n","                })\n","            elif tag.tag == \"TLINK\":\n","                tlinks.append({\n","                    \"fromID\": tag.attrib[\"fromID\"],\n","                    \"toID\": tag.attrib[\"toID\"],\n","                    \"type\": tag.attrib[\"type\"]\n","                })\n","\n","        data.append((events, timex3s, tlinks, text))\n","    return data\n","\n","# Function to link treatments with dates and annotate all time expressions\n","def link_treatments_with_dates(treatments, timex3s, tlinks, text):\n","    linked_data = {}\n","    for treatment in treatments:\n","        treatment_id = treatment[\"id\"]\n","        if treatment_id not in linked_data:\n","            linked_data[treatment_id] = {\n","                \"treatment\": treatment,\n","                \"dates\": [],\n","                \"text\": text,\n","                \"bio_time\": [\"O\"] * len(text),\n","                \"bio_treatment\": [\"O\"] * len(text),\n","                \"bio_tlink\": [\"O\"] * len(text)\n","            }\n","\n","        # Annotate all time expressions\n","        for timex in timex3s:\n","            bio_label = \"B-DATE\"\n","            linked_data[treatment_id][\"bio_time\"][timex[\"start\"]] = bio_label\n","            for i in range(timex[\"start\"] + 1, timex[\"end\"]):\n","                linked_data[treatment_id][\"bio_time\"][i] = \"I-DATE\"\n","\n","        # Annotate linked dates with TLINK types\n","        for tlink in tlinks:\n","            if tlink[\"fromID\"] == treatment_id or tlink[\"toID\"] == treatment_id:\n","                date_id = tlink[\"toID\"] if tlink[\"fromID\"] == treatment_id else tlink[\"fromID\"]\n","                date = next((t for t in timex3s if t[\"id\"] == date_id), None)\n","                if date:\n","                    linked_data[treatment_id][\"dates\"].append({\n","                        \"date\": date,\n","                        \"tlink_type\": tlink[\"type\"]\n","                    })\n","                    bio_label = f\"B-{tlink['type']}\"\n","                    linked_data[treatment_id][\"bio_tlink\"][date[\"start\"]] = bio_label\n","                    for i in range(date[\"start\"] + 1, date[\"end\"]):\n","                        linked_data[treatment_id][\"bio_tlink\"][i] = f\"I-{tlink['type']}\"\n","\n","        # Annotate treatments\n","        bio_label_treatment = \"B-TREATMENT\"\n","        linked_data[treatment_id][\"bio_treatment\"][treatment[\"start\"]] = bio_label_treatment\n","        for i in range(treatment[\"start\"] + 1, treatment[\"end\"]):\n","            linked_data[treatment_id][\"bio_treatment\"][i] = \"I-TREATMENT\"\n","\n","    return linked_data.values()\n","\n","# Function to align BIO annotations with tokenized text\n","def align_bio_with_tokens(text, bio_annotations, tokenizer):\n","    tokens = tokenizer.tokenize(text)\n","    token_offsets = tokenizer(text, return_offsets_mapping=True)[\"offset_mapping\"]\n","    # print(\"Token Offsets and Corresponding Tokens:\")\n","    # for token, (token_start, token_end) in zip(tokens, token_offsets):\n","    #     print(f\"Token: {token}, Start: {token_start}, End: {token_end}\")\n","    aligned_bio = []\n","    prev_tag = \"O\"\n","    for token_start, token_end in token_offsets:\n","        if token_start == token_end:\n","            continue\n","        if token_start >= len(bio_annotations):\n","            aligned_bio.append(\"O\")\n","            # print(f\"Token start {token_start} exceeds BIO annotations length {len(bio_annotations)}, appending 'O'\")\n","            continue\n","\n","        bio_tag = bio_annotations[token_start]\n","        if bio_tag.startswith(\"I-\") and prev_tag == \"O\":\n","            bio_tag = \"B-\" + bio_tag[2:]\n","        aligned_bio.append(bio_tag)\n","        prev_tag = bio_tag\n","    # print(aligned_bio)\n","    # Debugging: Print tokens and corresponding BIO tags that are not \"O\"\n","    # for token, bio_tag in zip(tokens, aligned_bio):\n","    #     if bio_tag != \"O\":\n","    #         print(f\"Token: {token}, BIO Tag: {bio_tag}\")\n","\n","    return tokens, aligned_bio\n","\n","# Function to chunk annotations around target sentences\n","def chunk_annotations(text, bio_time, bio_treatment, bio_tlink, tokenizer, window_size):\n","    # Tokenize text into sentences\n","    doc = nlp(text)\n","    sentences = list(doc.sents)\n","\n","    # Find sentence boundaries\n","    sentence_boundaries = [(sent.start_char, sent.end_char) for sent in sentences]\n","\n","    # Identify sentences containing target entities\n","    target_indices = []\n","    for i, (start, end) in enumerate(sentence_boundaries):\n","        if (any(tag.startswith(\"B-\") or tag.startswith(\"I-\") for tag in bio_time[start:end]) or\n","                any(tag.startswith(\"B-\") or tag.startswith(\"I-\") for tag in bio_treatment[start:end]) or\n","                    any(tag.startswith(\"B-\") or tag.startswith(\"I-\") for tag in bio_tlink[start:end])):\n","            target_indices.append(i)\n","\n","    # Extract sentences around target indices based on window size\n","    selected_indices = set()\n","    for idx in target_indices:\n","        start_idx = max(0, idx - window_size)\n","        end_idx = min(len(sentences), idx + window_size + 1)\n","        selected_indices.update(range(start_idx, end_idx))\n","\n","    # Combine selected sentences and update BIO annotations\n","    selected_indices = sorted(selected_indices)\n","    selected_text = \" \".join([sentences[i].text for i in selected_indices])\n","\n","    selected_bio_time = []\n","    selected_bio_treatment = []\n","    selected_bio_tlink = []\n","\n","    for idx in selected_indices:\n","        start, end = sentence_boundaries[idx]\n","        selected_bio_time.extend(bio_time[start:end])\n","        selected_bio_treatment.extend(bio_treatment[start:end])\n","        selected_bio_tlink.extend(bio_tlink[start:end])\n","\n","    # Debugging: Print selected sentences and BIO annotations\n","    # print(\"Selected Sentences:\\n\", selected_text)\n","    # print(\"Selected BIO Time (non-O):\")\n","    # for i, tag in enumerate(selected_bio_time):\n","    #     if tag != \"O\":\n","    #         print(f\"Token: {selected_text[i]}, BIO Tag: {tag}\")\n","\n","    # print(\"Selected BIO Treatment (non-O):\")\n","    # for i, tag in enumerate(selected_bio_treatment):\n","    #     if tag != \"O\":\n","    #         print(f\"Token: {selected_text[i]}, BIO Tag: {tag}\")\n","\n","    # print(\"Selected BIO TLINK (non-O):\")\n","    # for i, tag in enumerate(selected_bio_tlink):\n","    #     if tag != \"O\":\n","    #         print(f\"Token: {selected_text[i]}, BIO Tag: {tag}\")\n","\n","    # Align new selected text with BERT tokens\n","\n","    tokens, aligned_bio_time = align_bio_with_tokens(selected_text, selected_bio_time, tokenizer)\n","    _, aligned_bio_treatment = align_bio_with_tokens(selected_text, selected_bio_treatment, tokenizer)\n","    _, aligned_bio_tlink = align_bio_with_tokens(selected_text, selected_bio_tlink, tokenizer)\n","\n","    return selected_text, tokens, aligned_bio_time, aligned_bio_treatment, aligned_bio_tlink\n","\n","\n","# Main processing\n","xml_dir = \"/content/drive/MyDrive/UOM_year3/3rd_year_project/2012_Temporal_Relations_Challenge/2012-07-06.release-fix\"\n","xml_data = parse_xml_files(xml_dir)\n","extracted_data = extract_entities(xml_data)\n","# temp = extracted_data[0:1]\n","# print(temp)\n","linked_treatments = []\n","for events, timex3s, tlinks, text in extracted_data:\n","    linked_treatments.extend(link_treatments_with_dates(events, timex3s, tlinks, text))\n","# print(\"/////////\")\n","# print(linked_treatments)\n","# Align BIO annotations with BERT tokens for each entry\n","window_size = 2\n","processed_data = []\n","for entry in linked_treatments:\n","    text = entry[\"text\"]\n","    bio_time = entry[\"bio_time\"]\n","    bio_treatment = entry[\"bio_treatment\"]\n","    bio_tlink = entry[\"bio_tlink\"]\n","\n","    try:\n","        selected_text, tokens, aligned_bio_time, aligned_bio_treatment, aligned_bio_tlink = chunk_annotations(\n","            text, bio_time, bio_treatment, bio_tlink, tokenizer, window_size\n","        )\n","\n","        # processed_data.append({\n","        #     \"selected_text\": selected_text,\n","        #     \"tokens\": tokens,\n","        #     \"aligned_bio_time\": aligned_bio_time,\n","        #     \"aligned_bio_treatment\": aligned_bio_treatment,\n","        #     \"aligned_bio_tlink\": aligned_bio_tlink\n","        # })\n","        processed_data.append({\n","            \"tokens\": tokens,\n","            \"bio_time_aligned\": aligned_bio_tlink,\n","            \"bio_treatment_aligned\": aligned_bio_treatment,\n","        })\n","    except Exception as e:\n","        print(f\"Error processing entry with text: {text[:50]}... Error: {e}\")\n","\n","# Example output\n","# for entry in processed_data[:1]:  # printing only the first entry for brevity\n","#     print(\"Selected Text:\", entry[\"selected_text\"])\n","#     print(\"Tokens:\", entry[\"tokens\"])\n","#     print(len(entry[\"tokens\"]))\n","#     print(\"Aligned BIO Time:\", entry[\"aligned_bio_time\"])\n","#     print(len(entry[\"aligned_bio_time\"]))\n","#     print(\"Aligned BIO Treatment:\", entry[\"aligned_bio_treatment\"])\n","#     print(len(entry[\"aligned_bio_treatment\"]))\n","#     print(\"Aligned BIO TLINK:\", entry[\"aligned_bio_tlink\"])\n","#     print(len(entry[\"aligned_bio_tlink\"]))\n","#     print(\"\\n\")\n","\n","#     # Collect non-O entities for BIO time annotations\n","#     bio_time_entities = []\n","#     current_entity = []\n","#     current_label = None\n","#     for token, bio_tag in zip(entry[\"tokens\"], entry[\"aligned_bio_time\"]):\n","#         if bio_tag.startswith(\"B-\"):\n","#             if current_entity:\n","#                 bio_time_entities.append((current_label, current_entity))\n","#                 current_entity = []\n","#             current_label = bio_tag[2:]\n","#             current_entity.append(token)\n","#         elif bio_tag.startswith(\"I-\") and current_label == bio_tag[2:]:\n","#             current_entity.append(token)\n","#         else:\n","#             if current_entity:\n","#                 bio_time_entities.append((current_label, current_entity))\n","#                 current_entity = []\n","#             current_label = None\n","\n","#     if current_entity:\n","#         bio_time_entities.append((current_label, current_entity))\n","\n","#     # Collect non-O entities for BIO treatment annotations\n","#     bio_treatment_entities = []\n","#     current_entity = []\n","#     current_label = None\n","#     for token, bio_tag in zip(entry[\"tokens\"], entry[\"aligned_bio_treatment\"]):\n","#         if bio_tag.startswith(\"B-\"):\n","#             if current_entity:\n","#                 bio_treatment_entities.append((current_label, current_entity))\n","#                 current_entity = []\n","#             current_label = bio_tag[2:]\n","#             current_entity.append(token)\n","#         elif bio_tag.startswith(\"I-\") and current_label == bio_tag[2:]:\n","#             current_entity.append(token)\n","#         else:\n","#             if current_entity:\n","#                 bio_treatment_entities.append((current_label, current_entity))\n","#                 current_entity = []\n","#             current_label = None\n","\n","#     if current_entity:\n","#         bio_treatment_entities.append((current_label, current_entity))\n","\n","#     # Collect non-O entities for BIO tlink annotations\n","#     bio_tlink_entities = []\n","#     current_entity = []\n","#     current_label = None\n","#     for token, bio_tag in zip(entry[\"tokens\"], entry[\"aligned_bio_tlink\"]):\n","#         if bio_tag.startswith(\"B-\"):\n","#             if current_entity:\n","#                 bio_tlink_entities.append((current_label, current_entity))\n","#                 current_entity = []\n","#             current_label = bio_tag[2:]\n","#             current_entity.append(token)\n","#         elif bio_tag.startswith(\"I-\") and current_label == bio_tag[2:]:\n","#             current_entity.append(token)\n","#         else:\n","#             if current_entity:\n","#                 bio_tlink_entities.append((current_label, current_entity))\n","#                 current_entity = []\n","#             current_label = None\n","\n","#     if current_entity:\n","#         bio_tlink_entities.append((current_label, current_entity))\n","\n","#     print(\"BIO Time Entities:\")\n","#     for label, tokens in bio_time_entities:\n","#         print(f\"Entity: {' '.join(tokens)}, Label: {label}\")\n","\n","#     print(\"\\nBIO Treatment Entities:\")\n","#     for label, tokens in bio_treatment_entities:\n","#         print(f\"Entity: {' '.join(tokens)}, Label: {label}\")\n","\n","#     print(\"\\nBIO TLINK Entities:\")\n","#     for label, tokens in bio_tlink_entities:\n","#         print(f\"Entity: {' '.join(tokens)}, Label: {label}\")\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51269,"status":"ok","timestamp":1724673989795,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":-480},"id":"2o5J5jgU0Iom","outputId":"38af5f13-50ac-4cc5-8192-9ed106e155ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Error parsing 397.xml, skipping...\n","Error parsing 527.xml, skipping...\n","Error parsing 627.xml, skipping...\n","Error parsing 53.xml, skipping...\n","Error parsing 687.xml, skipping...\n","Error parsing 802.xml, skipping...\n","114\n","114\n"]},{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (2061 > 512). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["2979\n","2979\n"]}],"source":["import os\n","import xml.etree.ElementTree as ET\n","import spacy\n","from transformers import BertTokenizerFast\n","\n","\n","# Directory containing the XML files\n","xml_dir = \"/content/drive/MyDrive/UOM_year3/3rd_year_project/2012_Temporal_Relations_Challenge/ground_truth/merged_xml\"\n","# xml_dir = \"/content/drive/MyDrive/UOM_year3/3rd_year_project/2012_Temporal_Relations_Challenge/2012-07-06.release-fix\"\n","# Initialize BERT tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","\n","# Function to read and parse XML files\n","def parse_xml_files(directory):\n","    data = []\n","    for filename in os.listdir(directory):\n","        if filename.endswith(\".xml\"):\n","            try:\n","                tree = ET.parse(os.path.join(directory, filename))\n","                root = tree.getroot()\n","                text_content = root.find(\"TEXT\").text\n","                data.append((root, text_content))\n","            except ET.ParseError:\n","                print(f\"Error parsing {filename}, skipping...\")\n","    return data\n","\n","# Function to extract EVENT and TIMEX3 entities\n","def extract_entities(xml_data):\n","    data = []\n","    for entry, text in xml_data:\n","        events = []\n","        timex3s = []\n","        tlinks = []\n","\n","        for tag in entry.find(\"TAGS\"):\n","            if tag.tag == \"EVENT\" and tag.attrib[\"type\"] == \"TREATMENT\":\n","                events.append({\n","                    \"id\": tag.attrib[\"id\"],\n","                    \"text\": tag.attrib[\"text\"],\n","                    \"start\": int(tag.attrib[\"start\"]),\n","                    \"end\": int(tag.attrib[\"end\"]),\n","                    \"modality\": tag.attrib[\"modality\"],\n","                    \"polarity\": tag.attrib[\"polarity\"]\n","                })\n","            elif tag.tag == \"TIMEX3\" and tag.attrib[\"type\"] == \"DATE\":\n","                timex3s.append({\n","                    \"id\": tag.attrib[\"id\"],\n","                    \"text\": tag.attrib[\"text\"],\n","                    \"start\": int(tag.attrib[\"start\"]),\n","                    \"end\": int(tag.attrib[\"end\"]),\n","                    \"val\": tag.attrib[\"val\"]\n","                })\n","            elif tag.tag == \"TLINK\":\n","                tlinks.append({\n","                    \"fromID\": tag.attrib[\"fromID\"],\n","                    \"toID\": tag.attrib[\"toID\"],\n","                    \"type\": tag.attrib[\"type\"]\n","                })\n","\n","        data.append((events, timex3s, tlinks, text))\n","    return data\n","\n","# Function to link treatments with dates and include TLINK type information\n","def link_treatments_with_dates(treatments, timex3s, tlinks, text):\n","    linked_data = {}\n","    for treatment in treatments:\n","        treatment_id = treatment[\"id\"]\n","        if treatment_id not in linked_data:\n","            linked_data[treatment_id] = {\n","                \"treatment\": treatment,\n","                \"dates\": [],\n","                \"text\": text,\n","                \"bio_time\": [\"O\"] * len(text),\n","                \"bio_treatment\": [\"O\"] * len(text)\n","            }\n","\n","        for tlink in tlinks:\n","            if tlink[\"fromID\"] == treatment_id or tlink[\"toID\"] == treatment_id:\n","                date_id = tlink[\"toID\"] if tlink[\"fromID\"] == treatment_id else tlink[\"fromID\"]\n","                date = next((t for t in timex3s if t[\"id\"] == date_id), None)\n","                if date:\n","                    linked_data[treatment_id][\"dates\"].append({\n","                        \"date\": date,\n","                        \"tlink_type\": tlink[\"type\"]\n","                    })\n","                    # Update BIO annotation for dates\n","                    bio_label = f\"B-{tlink['type']}\"\n","                    linked_data[treatment_id][\"bio_time\"][date[\"start\"]] = bio_label\n","                    for i in range(date[\"start\"] + 1, date[\"end\"]):\n","                        linked_data[treatment_id][\"bio_time\"][i] = f\"I-{tlink['type']}\"\n","\n","        # Update BIO annotation for treatments\n","        bio_label_treatment = \"B-TREATMENT\"\n","        linked_data[treatment_id][\"bio_treatment\"][treatment[\"start\"]] = bio_label_treatment\n","        for i in range(treatment[\"start\"] + 1, treatment[\"end\"]):\n","            linked_data[treatment_id][\"bio_treatment\"][i] = \"I-TREATMENT\"\n","\n","    return linked_data.values()\n","\n","# Function to align BIO annotations with tokenized text\n","def align_bio_with_tokens(text, bio_annotations, tokenizer):\n","    tokens = tokenizer.tokenize(text)\n","    token_offsets = tokenizer(text, return_offsets_mapping=True)[\"offset_mapping\"]\n","\n","    aligned_bio = []\n","    for token_start, token_end in token_offsets:\n","        if token_start == token_end:\n","            # there will be '[CLS]' and '[SEP]' at the begin and the end, so here we jump those. But in the model the '[CLS]' and '[SEP]' are tokens?\n","            # aligned_bio.append(\"O\")\n","            continue\n","        bio_tag = bio_annotations[token_start]\n","        aligned_bio.append(bio_tag)\n","\n","    return tokens, aligned_bio\n","\n","# Main processing\n","xml_data = parse_xml_files(xml_dir)\n","print(len(xml_data))\n","extracted_data = extract_entities(xml_data)\n","print(len(extracted_data))\n","linked_treatments = []\n","for events, timex3s, tlinks, text in extracted_data:\n","    linked_treatments.extend(link_treatments_with_dates(events, timex3s, tlinks, text))\n","print(len(linked_treatments))\n","# Align BIO annotations with BERT tokens for each entry\n","alignment_annotations=[]\n","for entry in linked_treatments:\n","    temp={}\n","    tokens, bio_time = align_bio_with_tokens(entry['text'], entry['bio_time'], tokenizer)\n","    _, bio_treatment = align_bio_with_tokens(entry['text'], entry['bio_treatment'], tokenizer)\n","    temp['tokens'] = tokens\n","    temp['bio_time_aligned'] = bio_time\n","    temp['bio_treatment_aligned'] = bio_treatment\n","    alignment_annotations.append(temp)\n","\n","# Example output\n","# for entry in linked_treatments:\n","#     print(\"Text:\", entry['text'])\n","#     print(\"Tokens:\", entry['tokens'])\n","#     print(\"BIO Time Aligned:\", entry['bio_time_aligned'])\n","#     print(\"BIO Treatment Aligned:\", entry['bio_treatment_aligned'])\n","#     print(\"\\n\")\n","# linked_treatments[0]\n","print(len(alignment_annotations))"]},{"cell_type":"markdown","metadata":{"id":"FPHecBma0zqq"},"source":["bert:[CLS] + {treatmeng} + [SEP] + {tokens}"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d3fa577bd73c495db71b22eb2a2fa1d6","3119789429ca4c30bd1a9b8325d5ef3f","deead8607ac64a5bb9df8f47bde496c3","6a112f744b16417785ed773e5767f162","37996f3c3ad244d79a049f3bf5114d18","68dfd9d8aba04388b3b5b23c9bb4481c","b5dc1b4e12c647e78f7b96afa15a9b26","17a1dfe6b93a4281af14a0fc45ca3238","912c8056b7d34771869ea8d1bb211dde","99f649797ec34390947a8f4a862647d7","97143fb56ade4b67820f8a010e4fb654"]},"executionInfo":{"elapsed":5422008,"status":"ok","timestamp":1724679411787,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":-480},"id":"ucG6Bu5R0zhG","outputId":"21b35486-2565-46db-dbf9-d68e24b6585f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Counts for each label: [871298   1690   6699    168    547    160    428]\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3fa577bd73c495db71b22eb2a2fa1d6"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","Train Loss: 0.0697\n","Validation Loss: 0.0236\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.56      0.76      0.64     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522704\n","   macro avg       0.22      0.25      0.23   1522704\n","weighted avg       0.99      0.99      0.99   1522704\n","\n","Epoch 2/20\n","Train Loss: 0.0226\n","Validation Loss: 0.0198\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.62      0.79      0.70      2722\n","    I-BEFORE       0.69      0.75      0.72     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522704\n","   macro avg       0.33      0.36      0.34   1522704\n","weighted avg       0.99      0.99      0.99   1522704\n","\n","Epoch 3/20\n","Train Loss: 0.0196\n","Validation Loss: 0.0198\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.59      0.82      0.69      2722\n","    I-BEFORE       0.64      0.80      0.71     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522704\n","   macro avg       0.32      0.37      0.34   1522704\n","weighted avg       0.99      0.99      0.99   1522704\n","\n","Epoch 4/20\n","Train Loss: 0.0182\n","Validation Loss: 0.0166\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.69      0.86      0.77      2722\n","    I-BEFORE       0.71      0.83      0.77     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522704\n","   macro avg       0.34      0.38      0.36   1522704\n","weighted avg       0.99      0.99      0.99   1522704\n","\n","Epoch 5/20\n","Train Loss: 0.0157\n","Validation Loss: 0.0219\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.73      0.79      0.76      2722\n","    I-BEFORE       0.74      0.79      0.76     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522704\n","   macro avg       0.35      0.37      0.36   1522704\n","weighted avg       0.99      0.99      0.99   1522704\n","\n","Epoch 6/20\n","Train Loss: 0.0142\n","Validation Loss: 0.0219\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.76      0.82      0.79      2722\n","    I-BEFORE       0.77      0.82      0.79     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           1.00   1522704\n","   macro avg       0.36      0.38      0.37   1522704\n","weighted avg       0.99      1.00      1.00   1522704\n","\n","Epoch 7/20\n","Train Loss: 0.0121\n","Validation Loss: 0.0200\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.71      0.79      0.75      2722\n","    I-BEFORE       0.73      0.79      0.76     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.27      0.01      0.01       490\n","\n","    accuracy                           1.00   1522704\n","   macro avg       0.39      0.37      0.36   1522704\n","weighted avg       0.99      1.00      0.99   1522704\n","\n","Epoch 8/20\n","Train Loss: 0.0110\n","Validation Loss: 0.0203\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.68      0.79      0.73      2722\n","    I-BEFORE       0.70      0.78      0.74     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.04      0.01      0.01       163\n","   I-OVERLAP       0.11      0.03      0.05       490\n","\n","    accuracy                           0.99   1522704\n","   macro avg       0.36      0.37      0.36   1522704\n","weighted avg       0.99      0.99      0.99   1522704\n","\n","Epoch 9/20\n","Train Loss: 0.0097\n","Validation Loss: 0.0203\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.79      0.84      0.81      2722\n","    I-BEFORE       0.79      0.86      0.82     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.23      0.04      0.06       163\n","   I-OVERLAP       0.55      0.04      0.08       490\n","\n","    accuracy                           1.00   1522704\n","   macro avg       0.48      0.40      0.40   1522704\n","weighted avg       1.00      1.00      1.00   1522704\n","\n","Epoch 10/20\n","Train Loss: 0.0079\n","Validation Loss: 0.0172\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.77      0.84      0.81      2722\n","    I-BEFORE       0.78      0.85      0.81     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.56      0.06      0.11       163\n","   I-OVERLAP       0.53      0.06      0.10       490\n","\n","    accuracy                           1.00   1522704\n","   macro avg       0.52      0.40      0.40   1522704\n","weighted avg       1.00      1.00      1.00   1522704\n","\n","Epoch 11/20\n","Train Loss: 0.0073\n","Validation Loss: 0.0220\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.76      0.83      0.79      2722\n","    I-BEFORE       0.76      0.84      0.80     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.45      0.06      0.11       163\n","   I-OVERLAP       0.59      0.04      0.08       490\n","\n","    accuracy                           1.00   1522704\n","   macro avg       0.51      0.40      0.40   1522704\n","weighted avg       1.00      1.00      1.00   1522704\n","\n","Epoch 12/20\n","Train Loss: 0.0066\n","Validation Loss: 0.0194\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.77      0.83      0.80      2722\n","    I-BEFORE       0.78      0.84      0.81     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.29      0.06      0.10       163\n","   I-OVERLAP       0.41      0.08      0.14       490\n","\n","    accuracy                           1.00   1522704\n","   macro avg       0.46      0.40      0.41   1522704\n","weighted avg       1.00      1.00      1.00   1522704\n","\n","Epoch 13/20\n","Train Loss: 0.0062\n","Validation Loss: 0.0205\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.77      0.84      0.80      2722\n","    I-BEFORE       0.77      0.84      0.81     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.24      0.07      0.11       163\n","   I-OVERLAP       0.41      0.10      0.16       490\n","\n","    accuracy                           1.00   1522704\n","   macro avg       0.46      0.41      0.41   1522704\n","weighted avg       1.00      1.00      1.00   1522704\n","\n","Epoch 14/20\n","Train Loss: 0.0059\n","Validation Loss: 0.0199\n","              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.76      0.81      0.79      2722\n","    I-BEFORE       0.77      0.81      0.79     10762\n","     B-AFTER       0.33      0.01      0.03       224\n","     I-AFTER       0.47      0.01      0.02       856\n","   B-OVERLAP       0.33      0.09      0.14       163\n","   I-OVERLAP       0.59      0.06      0.10       490\n","\n","    accuracy                           1.00   1522704\n","   macro avg       0.61      0.40      0.41   1522704\n","weighted avg       1.00      1.00      1.00   1522704\n","\n","Epoch 15/20\n","Train Loss: 0.0050\n","Validation Loss: 0.0200\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.78      0.87      0.82      2722\n","    I-BEFORE       0.79      0.87      0.83     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.18      0.07      0.11       163\n","   I-OVERLAP       0.28      0.05      0.09       490\n","\n","    accuracy                           1.00   1522704\n","   macro avg       0.43      0.41      0.41   1522704\n","weighted avg       1.00      1.00      1.00   1522704\n","\n","Epoch 16/20\n","Train Loss: 0.0047\n","Validation Loss: 0.0190\n","              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.80      0.85      0.82      2722\n","    I-BEFORE       0.80      0.86      0.83     10762\n","     B-AFTER       0.25      0.01      0.02       224\n","     I-AFTER       0.17      0.01      0.01       856\n","   B-OVERLAP       0.16      0.10      0.13       163\n","   I-OVERLAP       0.30      0.07      0.12       490\n","\n","    accuracy                           1.00   1522704\n","   macro avg       0.50      0.41      0.42   1522704\n","weighted avg       1.00      1.00      1.00   1522704\n","\n","Epoch 17/20\n","Train Loss: 0.0045\n","Validation Loss: 0.0221\n","              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.79      0.82      0.80      2722\n","    I-BEFORE       0.79      0.83      0.81     10762\n","     B-AFTER       0.33      0.01      0.03       224\n","     I-AFTER       0.28      0.01      0.02       856\n","   B-OVERLAP       0.29      0.09      0.13       163\n","   I-OVERLAP       0.31      0.08      0.12       490\n","\n","    accuracy                           1.00   1522704\n","   macro avg       0.54      0.41      0.42   1522704\n","weighted avg       1.00      1.00      1.00   1522704\n","\n","Epoch 18/20\n","Train Loss: 0.0038\n","Validation Loss: 0.0224\n","              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.80      0.85      0.82      2722\n","    I-BEFORE       0.81      0.84      0.82     10762\n","     B-AFTER       0.50      0.01      0.03       224\n","     I-AFTER       0.24      0.05      0.08       856\n","   B-OVERLAP       0.23      0.07      0.11       163\n","   I-OVERLAP       0.24      0.06      0.09       490\n","\n","    accuracy                           1.00   1522704\n","   macro avg       0.55      0.41      0.42   1522704\n","weighted avg       1.00      1.00      1.00   1522704\n","\n","Epoch 19/20\n","Train Loss: 0.0038\n","Validation Loss: 0.0218\n","              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.79      0.80      0.79      2722\n","    I-BEFORE       0.80      0.81      0.81     10762\n","     B-AFTER       0.14      0.10      0.12       224\n","     I-AFTER       0.15      0.08      0.10       856\n","   B-OVERLAP       0.16      0.13      0.14       163\n","   I-OVERLAP       0.18      0.09      0.12       490\n","\n","    accuracy                           1.00   1522704\n","   macro avg       0.46      0.43      0.44   1522704\n","weighted avg       1.00      1.00      1.00   1522704\n","\n","Epoch 20/20\n","Train Loss: 0.0033\n","Validation Loss: 0.0236\n","              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507487\n","    B-BEFORE       0.78      0.81      0.79      2722\n","    I-BEFORE       0.78      0.82      0.80     10762\n","     B-AFTER       0.17      0.03      0.05       224\n","     I-AFTER       0.18      0.03      0.06       856\n","   B-OVERLAP       0.16      0.12      0.14       163\n","   I-OVERLAP       0.16      0.12      0.14       490\n","\n","    accuracy                           1.00   1522704\n","   macro avg       0.46      0.42      0.43   1522704\n","weighted avg       1.00      1.00      1.00   1522704\n","\n","Sample tokens: ['admission', 'date', ':', '2014', '-', '11', '-', '29', 'discharge', 'date', ':', '2014', '-', '12', '-', '05', 'service', ':', 'medicine', 'history', 'of', 'present', 'illness', ':', '47', 'yo', 'f', 'w', '/', 'h', '/', 'o', 'ste', '##roid', '-', 'induced', 'hyper', '##gly', '##ce', '##mia', ',', 'sl', '##e', 'w', '/', 'h', '/', 'o', 'per', '##ica', '##rdi', '##tis', ',', 'transverse', 'my', '##eli', '##tis', 'w', '/', 'para', '##ple', '##gia', 'and', 'ne', '##uro', '##genic', 'bladder', 's', '/', 'p', 'ur', '##ost', '##omy', 'w', '/', 'ile', '##al', 'con', '##du', '##it', ',', 'h', '/', 'o', 'ur', '##eter', '##ope', '##l', '##vic', 'stone', 'and', 'ur', '##ose', '##psis', ',', 'and', 'h', '/', 'o', 'r', '##le', 'd', '##v', '##t', 'a', '/', 'w', 'f', '2014', '-', '11', '-', '29', 'transferred', 'to', 'cm', '##ed', '2014', '-', '11', '-', '30', 'for', 'h', '##yp', '##ot', '##n', 'resistant', 'to', 'iv', '##fs', 'and', 'stress', 'ste', '##roids', '.', 'patient', 'initially', 'p', '/', 'w', 'c', '/', 'o', 'sudden', 'onset', 'n', '/', 'abd', 'pain', '/', 'chill', '##s', 'w', '/', 't', '103', 'at', 'nh', '.', 'rig', '##ors', 'progressed', 'so', 'she', 'was', 'brought', 'to', 'robert', '.', 'she', 'reported', 'h', '/', 'o', 'fatigue', 'and', 'an', '##ore', '##xia', 'for', 'the', 'past', 'few', 'days', 'and', 'had', 'noticed', 'foul', 'smelling', 'urine', 'and', 'some', 'abdominal', 'di', '##sten', '##sion', ',', 'similar', 'to', 'prior', 'episodes', 'of', 'p', '##ye', '##lo', '.', 'she', 'also', 'c', '/', 'o', 'll', '##q', 'and', 'groin', 'pain', 'which', 'responded', 'to', 'ty', '##len', '##ol', '.', 'she', 'denies', 'v', 'or', 'd', '.', 'no', 'am', '##s', '.', 'no', 'c', '/', 'o', 'cp', '.', 'on', 'arrival', 'to', 'shirley', ',', 'temperature', 'was', '101', '.', '2', '.', 'ct', 'abd', 'showed', 'an', '8', 'mm', 'right', 'pro', '##xi', '##mal', 'ur', '##eter', '##al', 'stone', 'with', 'right', '-', 'sided', 'hydro', '##ne', '##ph', '##rosis', 'and', 'inflammatory', 'strand', '##ing', ',', 'in', 'addition', 'to', 'p', '##ye', '##lone', '##ph', '##rit', '##is', 'of', 'the', 'left', 'kidney', 'without', 'left', 'sided', 'hydro', '##ne', '##ph', '##rosis', '.', 'labs', 'were', 'remarkable', 'for', 'wb', '##c', '23', '.', '5', 'w', '/', '1', '%', 'bands', 'which', 'decreased', 'to', '14', 'today', 'but', 'now', 'w', '/', '15', '%', 'bands', 'on', '#', 'van', '##c', '#', '(', 'h', '/', 'o', 'mrs', '##a', 'ur', '##ose', '##psis', ')', 'and', 'gen', '##t', '(', 'mu', '##lt', 'drug', 'all', '##er', '##gies', ')', '.', 'ag', 'on', 'admission', '18', '(', 'bi', '##car', '##b', '17', ',', 'down', 'from', '23', 'on', 'a', 'previous', 'admission', ')', ',', 'down', 'to', 'ag', '15', 'this', 'am', '.', 'ab', '##g', 'prior', 'to', 'transfer', '(', 'on', 'room', 'air', ')', ':', '7', '.', '43', '/', '24', '/', '69', 'w', '/', 'lac', '##tate', '1', '.', '3', '(', 'down', 'from', '1', '.', '4', 'on', 'the', 'prior', 'day', ')', '.', 'currently', ',', '03', '-', '14', 'blood', 'c', '##x', 'are', 'growing', 'g', '##nr', 'in', 'both', 'ana', '##ero', '##bic', 'bottles', '.', 'urine', 'c', '##x', 'is', 'pending', '.', 'prior', 'to', 'transfer', ',', 'patient', 'dropped', 'bp', 'to', '68', '/', '40', '##s', '.', 'bp', 'did', 'not', 'improve', 'despite', '2', 'l', 'ns', 'and', '100', 'mg', 'iv', 'hydro', '##cor', '##tis', '##one', '.', 'a', 'central', 'line', 'was', 'placed', 'and', 'she', 'was', 'sent', 'to', 'ir', 'for', 'a', 'right', 'ne', '##ph', '##ros', '##tom', '##y', 'tube', '.', 'brief', 'hospital', 'course', ':', '47', 'yo', 'f', 'w', '/', 'h', '/', 'o', 'ste', '##roid', '-', 'induced', 'hyper', '##gly', '##ce', '##mia', ',']\n","Sample true labels: [0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Sample predictions: [0 0 0 0 0 0 0 0 0 0 0 1 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import BertModel, BertTokenizerFast\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import numpy as np\n","\n","# Define a custom dataset class\n","class SequenceLabelingDataset(Dataset):\n","    def __init__(self, tokens, labels):\n","        self.tokens = tokens\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.tokens)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.tokens[idx],\n","            'labels': self.labels[idx]\n","        }\n","\n","# Custom collate function to pad sequences\n","def collate_fn(batch):\n","    max_len = max([len(x['input_ids']) for x in batch])\n","\n","    input_ids = []\n","    labels = []\n","\n","    for item in batch:\n","        input_ids.append(item['input_ids'] + [0] * (max_len - len(item['input_ids'])))\n","        labels.append(item['labels'] + [0] * (max_len - len(item['labels'])))\n","\n","    return {\n","        'input_ids': torch.tensor(input_ids, dtype=torch.long),\n","        'labels': torch.tensor(labels, dtype=torch.long)\n","    }\n","\n","# Prepare the data\n","def prepare_data(alignment_annotations, tokenizer, max_len=512):\n","    label_to_id = {\n","        \"O\": 0,\n","        \"B-BEFORE\": 1,\n","        \"I-BEFORE\": 2,\n","        \"B-AFTER\": 3,\n","        \"I-AFTER\": 4,\n","        \"B-OVERLAP\": 5,\n","        \"I-OVERLAP\": 6\n","    }\n","\n","    tokens, labels = [], []\n","\n","    for entry in alignment_annotations:\n","        modified_tokens = []\n","        modified_labels = []\n","\n","        treatment_started = False\n","        for token, treatment_tag, time_tag in zip(entry['tokens'], entry['bio_treatment_aligned'], entry['bio_time_aligned']):\n","            if treatment_tag == \"B-TREATMENT\" and not treatment_started:\n","                modified_tokens.append(\"#\")\n","                modified_labels.append(\"O\")\n","                treatment_started = True\n","\n","            modified_tokens.append(token)\n","            modified_labels.append(time_tag)\n","\n","            if treatment_tag == \"I-TREATMENT\" and treatment_started:\n","                next_index = entry['tokens'].index(token) + 1\n","                if next_index >= len(entry['tokens']) or entry['bio_treatment_aligned'][next_index] != \"I-TREATMENT\":\n","                    modified_tokens.append(\"#\")\n","                    modified_labels.append(\"O\")\n","                    treatment_started = False\n","\n","        token_ids = tokenizer.convert_tokens_to_ids(modified_tokens)\n","        label_ids = [label_to_id.get(tag, 0) for tag in modified_labels]\n","\n","        if len(token_ids) > max_len:\n","            token_ids = token_ids[:max_len]\n","            label_ids = label_ids[:max_len]\n","\n","        tokens.append(token_ids)\n","        labels.append(label_ids)\n","\n","    return tokens, labels\n","\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","test_tokens, test_labels = prepare_data(alignment_annotations, tokenizer)\n","train_tokens, train_labels = prepare_data(processed_data, tokenizer)\n","# Split data into training and test sets\n","# train_tokens, test_tokens, train_labels, test_labels = train_test_split(\n","#     tokens, labels, test_size=0.2, random_state=42\n","# )\n","\n","train_dataset = SequenceLabelingDataset(train_tokens, train_labels)\n","test_dataset = SequenceLabelingDataset(test_tokens, test_labels)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n","test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n","unique_labels, counts = np.unique(np.concatenate(train_labels), return_counts=True)\n","\n","print(\"Counts for each label:\", counts)\n","# Define the BERT model without additional positional encoding\n","class BertForSequenceLabeling(nn.Module):\n","    def __init__(self, num_labels=7):\n","        super(BertForSequenceLabeling, self).__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","        self.dropout = nn.Dropout(0.3)\n","        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n","\n","    def forward(self, input_ids):\n","        outputs = self.bert(input_ids)\n","        sequence_output = outputs.last_hidden_state\n","        sequence_output = self.dropout(sequence_output)\n","        logits = self.classifier(sequence_output)\n","        return logits\n","\n","# Initialize the model\n","model = BertForSequenceLabeling(num_labels=7)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n","\n","# Training function\n","def train(model, dataloader, optimizer, criterion, device):\n","    model.train()\n","    total_loss = 0\n","    for batch in dataloader:\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids)\n","        loss = criterion(outputs.view(-1, 7), labels.view(-1))\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","    return total_loss / len(dataloader)\n","\n","# Evaluation function\n","def evaluate(model, dataloader, criterion, device):\n","    model.eval()\n","    total_loss = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            input_ids = batch['input_ids'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids)\n","            loss = criterion(outputs.view(-1, 7), labels.view(-1))\n","\n","            total_loss += loss.item()\n","\n","            preds = torch.argmax(outputs, dim=-1).cpu().numpy()\n","            all_preds.extend(preds.flatten())\n","            all_labels.extend(labels.cpu().numpy().flatten())\n","\n","    return total_loss / len(dataloader), all_preds, all_labels\n","\n","# Training loop\n","\n","epochs = 20\n","for epoch in range(epochs):\n","    train_loss = train(model, train_dataloader, optimizer, criterion, device)\n","\n","    val_loss, val_preds, val_labels = evaluate(model, test_dataloader, criterion, device)\n","\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","    print(classification_report(val_labels, val_preds, target_names=['O', 'B-BEFORE', 'I-BEFORE', 'B-AFTER', 'I-AFTER', 'B-OVERLAP', 'I-OVERLAP']))\n","\n","# Output an example of evaluation\n","sample_input = test_tokens[0]\n","sample_labels = test_labels[0]\n","\n","model.eval()\n","with torch.no_grad():\n","    input_ids = torch.tensor(sample_input).unsqueeze(0).to(device)\n","    outputs = model(input_ids)\n","    preds = torch.argmax(outputs, dim=-1).cpu().numpy().flatten()\n","\n","print(\"Sample tokens:\", tokenizer.convert_ids_to_tokens(sample_input))\n","print(\"Sample true labels:\", sample_labels)\n","print(\"Sample predictions:\", preds)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"elapsed":3727,"status":"error","timestamp":1724568009018,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":-480},"id":"tswXmpO1IaOg","outputId":"a4acd0c7-b1b3-47a8-eb84-50024e9038b0"},"outputs":[{"ename":"ValueError","evalue":"too many values to unpack (expected 2)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-3570f15d8c16>\u001b[0m in \u001b[0;36m<cell line: 94>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;31m# tokens, labels, id_to_label = prepare_data(alignment_annotations, tokenizer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mtest_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malignment_annotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0mtrain_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import BertModel, BertTokenizerFast\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import numpy as np\n","\n","# Define a custom dataset class\n","class SequenceLabelingDataset(Dataset):\n","    def __init__(self, tokens, labels):\n","        self.tokens = tokens\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.tokens)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.tokens[idx],\n","            'labels': self.labels[idx]\n","        }\n","\n","# Custom collate function to pad sequences\n","def collate_fn(batch):\n","    max_len = max([len(x['input_ids']) for x in batch])\n","\n","    input_ids = []\n","    labels = []\n","\n","    for item in batch:\n","        input_ids.append(item['input_ids'] + [0] * (max_len - len(item['input_ids'])))\n","        labels.append(item['labels'] + [0] * (max_len - len(item['labels'])))\n","\n","    return {\n","        'input_ids': torch.tensor(input_ids, dtype=torch.long),\n","        'labels': torch.tensor(labels, dtype=torch.long)\n","    }\n","\n","# Prepare the data\n","def prepare_data(alignment_annotations, tokenizer, max_len=512):\n","    label_to_id = {\n","        \"O\": 0,\n","        \"B-BEFORE\": 1,\n","        \"I-BEFORE\": 2,\n","        \"B-AFTER\": 3,\n","        \"I-AFTER\": 4,\n","        \"B-OVERLAP\": 5,\n","        \"I-OVERLAP\": 6\n","    }\n","    id_to_label = {v: k for k, v in label_to_id.items()}\n","\n","    tokens, labels = [], []\n","\n","    for entry in alignment_annotations:\n","        modified_tokens = []\n","        modified_labels = []\n","\n","        treatment_started = False\n","        for i, (token, treatment_tag, time_tag) in enumerate(zip(entry['tokens'], entry['bio_treatment_aligned'], entry['bio_time_aligned'])):\n","            if treatment_tag == \"B-TREATMENT\" and not treatment_started:\n","                modified_tokens.append(\"#\")\n","                modified_labels.append(\"O\")\n","                treatment_started = True\n","\n","            modified_tokens.append(token)\n","            modified_labels.append(time_tag)\n","\n","            if (treatment_tag == \"I-TREATMENT\" or treatment_tag == \"B-TREATMENT\") and treatment_started:\n","                next_index = i + 1\n","                if next_index >= len(entry['tokens']) or entry['bio_treatment_aligned'][next_index] not in [\"I-TREATMENT\", \"B-TREATMENT\"]:\n","                    modified_tokens.append(\"#\")\n","                    modified_labels.append(\"O\")\n","                    treatment_started = False\n","\n","        token_ids = tokenizer.convert_tokens_to_ids(modified_tokens)\n","        label_ids = [label_to_id.get(tag, 0) for tag in modified_labels]\n","\n","        if len(token_ids) > max_len:\n","            token_ids = token_ids[:max_len]\n","            label_ids = label_ids[:max_len]\n","\n","        tokens.append(token_ids)\n","        labels.append(label_ids)\n","\n","    return tokens, labels, id_to_label\n","\n","# Load data and prepare datasets\n","\n","\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","# tokens, labels, id_to_label = prepare_data(alignment_annotations, tokenizer)\n","\n","test_tokens, test_labels = prepare_data(alignment_annotations, tokenizer)\n","train_tokens, train_labels = prepare_data(processed_data, tokenizer)\n","\n","# Split data into training and test sets\n","# train_tokens, test_tokens, train_labels, test_labels = train_test_split(\n","#     tokens, labels, test_size=0.2, random_state=42\n","# )\n","\n","train_dataset = SequenceLabelingDataset(train_tokens, train_labels)\n","test_dataset = SequenceLabelingDataset(test_tokens, test_labels)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n","test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n","\n","# Define the BERT model without additional positional encoding\n","class BertForSequenceLabeling(nn.Module):\n","    def __init__(self, num_labels=7):\n","        super(BertForSequenceLabeling, self).__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","        self.dropout = nn.Dropout(0.3)\n","        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n","\n","    def forward(self, input_ids):\n","        outputs = self.bert(input_ids)\n","        sequence_output = outputs.last_hidden_state\n","        sequence_output = self.dropout(sequence_output)\n","        logits = self.classifier(sequence_output)\n","        return logits\n","\n","# Initialize the model\n","model = BertForSequenceLabeling(num_labels=7)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n","\n","# Training function\n","def train(model, dataloader, optimizer, criterion, device):\n","    model.train()\n","    total_loss = 0\n","    for batch in dataloader:\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids)\n","        loss = criterion(outputs.view(-1, 7), labels.view(-1))\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","    return total_loss / len(dataloader)\n","\n","# Helper function to extract entities from BIO labels\n","def get_entities(seq, id_to_label):\n","    \"\"\"Gets entities from sequence of label IDs.\n","    Args:\n","        seq (list): sequence of label IDs.\n","    Returns:\n","        list: list of (chunk_type, chunk_start, chunk_end).\n","    \"\"\"\n","    chunks = []\n","    chunk_type, chunk_start = None, None\n","\n","    for i, label_id in enumerate(seq):\n","        label = id_to_label[label_id]\n","        if label.startswith(\"B-\"):\n","            if chunk_type is not None:\n","                chunks.append((chunk_type, chunk_start, i - 1))\n","            chunk_type = label.split(\"-\")[1]\n","            chunk_start = i\n","        elif label.startswith(\"I-\") and chunk_type is not None:\n","            continue\n","        else:\n","            if chunk_type is not None:\n","                chunks.append((chunk_type, chunk_start, i - 1))\n","                chunk_type, chunk_start = None, None\n","\n","    if chunk_type is not None:\n","        chunks.append((chunk_type, chunk_start, len(seq) - 1))\n","\n","    return chunks\n","\n","# Evaluation function at entity level\n","def evaluate(model, dataloader, criterion, device, id_to_label):\n","    model.eval()\n","    total_loss = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            input_ids = batch['input_ids'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids)\n","            loss = criterion(outputs.view(-1, 7), labels.view(-1))\n","\n","            total_loss += loss.item()\n","\n","            preds = torch.argmax(outputs, dim=-1).cpu().numpy()\n","            all_preds.extend(preds)\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    all_true_entities = []\n","    all_pred_entities = []\n","\n","    for true_seq, pred_seq in zip(all_labels, all_preds):\n","        true_entities = get_entities(true_seq, id_to_label)\n","        pred_entities = get_entities(pred_seq, id_to_label)\n","        all_true_entities.extend(true_entities)\n","        all_pred_entities.extend(pred_entities)\n","\n","    # Only keep entities for the target labels\n","    target_labels = ['BEFORE', 'AFTER', 'OVERLAP']\n","    filtered_true_entities = [entity for entity in all_true_entities if entity[0] in target_labels]\n","    filtered_pred_entities = [entity for entity in all_pred_entities if entity[0] in target_labels]\n","\n","    true_entity_labels = [entity[0] for entity in filtered_true_entities]\n","    pred_entity_labels = [entity[0] for entity in filtered_pred_entities]\n","\n","    report = classification_report(\n","        true_entity_labels,\n","        pred_entity_labels,\n","        labels=target_labels,\n","        target_names=target_labels\n","    )\n","\n","    return total_loss / len(dataloader), report\n","\n","# Training loop\n","epochs = 10\n","for epoch in range(epochs):\n","    train_loss = train(model, train_dataloader, optimizer, criterion, device)\n","    val_loss, val_report = evaluate(model, test_dataloader, criterion, device, id_to_label)\n","\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","    print(val_report)\n","\n","# Output an example of evaluation\n","sample_input = test_tokens[0]\n","sample_labels = test_labels[0]\n","\n","model.eval()\n","with torch.no_grad():\n","    input_ids = torch.tensor(sample_input).unsqueeze(0).to(device)\n","    outputs = model(input_ids)\n","    preds = torch.argmax(outputs, dim=-1).cpu().numpy().flatten()\n","\n","print(\"Sample tokens:\", tokenizer.convert_ids_to_tokens(sample_input))\n","print(\"Sample true labels:\", sample_labels)\n","print(\"Sample predictions:\", preds)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["55d71e8b8502480c8eb7fb1d9ef56753","788d7a29589744be905b2d1b24a31e74","aaefaac4bc264bc2899720eafec85068","6712b469ff6f46189d305dbf5c3a5e5d","5d532571a77a4d378eb861f911456e92","744594703bce462aae04ea8159f6f442","8a16f2bec7d34d1aa019fc99ba049fc8","644c2c406a0c444d929ba07ba9fd602e","a957393afeb74fa48c390cd703801a4f","f1232ec83abe4c11963c2bd99e6712e9","8cf54394449841aeb26c8b26dabc7a74"]},"id":"sBZQF362LDJF","executionInfo":{"status":"error","timestamp":1724657728508,"user_tz":-480,"elapsed":587043,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"}},"outputId":"af7c89e3-8e6c-433f-aa75-7d636d416808"},"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55d71e8b8502480c8eb7fb1d9ef56753"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","Train Loss: 0.0695\n","Validation Loss: 0.0235\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.56      0.75      0.64     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.22      0.25      0.23   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 2/10\n","Train Loss: 0.0228\n","Validation Loss: 0.0212\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.68      0.74      0.71      2722\n","    I-BEFORE       0.69      0.75      0.72     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.34      0.36      0.35   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-cd610554c7fb>\u001b[0m in \u001b[0;36m<cell line: 169>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-cd610554c7fb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import BertModel, BertTokenizerFast\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import numpy as np\n","\n","# Define a custom dataset class\n","class SequenceLabelingDataset(Dataset):\n","    def __init__(self, tokens, pos_encodings, labels):\n","        self.tokens = tokens\n","        self.pos_encodings = pos_encodings\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.tokens)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.tokens[idx],\n","            'pos_encodings': self.pos_encodings[idx],\n","            'labels': self.labels[idx]}\n","\n","# Custom collate function to pad sequences\n","def collate_fn(batch):\n","    max_len = max([len(x['input_ids']) for x in batch])\n","\n","    input_ids = []\n","    pos_encodings = []\n","    labels = []\n","\n","    for item in batch:\n","        input_ids.append(item['input_ids'] + [0] * (max_len - len(item['input_ids'])))\n","        pos_encodings.append(item['pos_encodings'] + [0] * (max_len - len(item['pos_encodings'])))\n","        labels.append(item['labels'] + [0] * (max_len - len(item['labels'])))\n","\n","    return {\n","        'input_ids': torch.tensor(input_ids, dtype=torch.long),\n","        'pos_encodings': torch.tensor(pos_encodings, dtype=torch.float),\n","        'labels': torch.tensor(labels, dtype=torch.long)\n","    }\n","\n","# Prepare the data\n","def prepare_data(alignment_annotations, tokenizer, max_len=512):\n","    label_to_id = {\n","        \"O\": 0,\n","        \"B-BEFORE\": 1,\n","        \"I-BEFORE\": 2,\n","        \"B-AFTER\": 3,\n","        \"I-AFTER\": 4,\n","        \"B-OVERLAP\": 5,\n","        \"I-OVERLAP\": 6\n","    }\n","\n","    tokens, pos_encodings, labels = [], [], []\n","\n","    for entry in alignment_annotations:\n","        token_ids = tokenizer.convert_tokens_to_ids(entry['tokens'])\n","        pos_encoding = [1 if tag == \"B-TREATMENT\" or tag == \"I-TREATMENT\" else 0 for tag in entry['bio_treatment_aligned']]\n","        label = [label_to_id.get(tag, 0) for tag in entry['bio_time_aligned']]  # default to 0 if tag not found\n","\n","        if len(token_ids) > max_len:\n","            token_ids = token_ids[:max_len]\n","            pos_encoding = pos_encoding[:max_len]\n","            label = label[:max_len]\n","\n","        tokens.append(token_ids)\n","        pos_encodings.append(pos_encoding)\n","        labels.append(label)\n","\n","    return tokens, pos_encodings, labels\n","\n","# Load data and prepare datasets\n","# tokens, pos_encodings, labels = prepare_data(alignment_annotations, tokenizer)\n","\n","# Split data into training and test sets\n","# train_tokens, test_tokens, train_pos, test_pos, train_labels, test_labels = train_test_split(\n","#     tokens, pos_encodings, labels, test_size=0.2, random_state=42\n","# )\n","\n","test_tokens, test_pos, test_labels = prepare_data(alignment_annotations, tokenizer)\n","train_tokens, train_pos, train_labels = prepare_data(processed_data, tokenizer)\n","\n","train_dataset = SequenceLabelingDataset(train_tokens, train_pos, train_labels)\n","test_dataset = SequenceLabelingDataset(test_tokens, test_pos, test_labels)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n","test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n","\n","# Define the BERT model with additional input for positional encoding\n","class BertForSequenceLabeling(nn.Module):\n","    def __init__(self, num_labels=7):\n","        super(BertForSequenceLabeling, self).__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","        self.dropout = nn.Dropout(0.3)\n","        self.classifier = nn.Linear(self.bert.config.hidden_size + 1, num_labels)\n","\n","    def forward(self, input_ids, pos_encodings):\n","        outputs = self.bert(input_ids)\n","        sequence_output = outputs.last_hidden_state\n","        # sequence_output torch.Size([16, 512, 768])\n","        # pos_encodings torch.Size([16, 512])\n","        # Concatenate positional encoding\n","\n","        pos_encodings = pos_encodings.unsqueeze(-1)\n","        # pos_encodings.unsqueeze(-1) torch.Size([16, 512, 1])\n","        sequence_output = torch.cat((sequence_output, pos_encodings), dim=-1)\n","        # torch.cat torch.Size([16, 512, 769])\n","\n","        sequence_output = self.dropout(sequence_output)\n","        logits = self.classifier(sequence_output)\n","\n","        return logits\n","\n","# Initialize the model\n","model = BertForSequenceLabeling(num_labels=7)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n","\n","# Training function\n","def train(model, dataloader, optimizer, criterion, device):\n","    model.train()\n","    total_loss = 0\n","    for batch in dataloader:\n","        input_ids = batch['input_ids'].to(device)\n","        pos_encodings = batch['pos_encodings'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, pos_encodings)\n","        loss = criterion(outputs.view(-1, 7), labels.view(-1))\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","    return total_loss / len(dataloader)\n","\n","# Evaluation function\n","def evaluate(model, dataloader, criterion, device):\n","    model.eval()\n","    total_loss = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            input_ids = batch['input_ids'].to(device)\n","            pos_encodings = batch['pos_encodings'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids, pos_encodings)\n","            loss = criterion(outputs.view(-1, 7), labels.view(-1))\n","\n","            total_loss += loss.item()\n","\n","            preds = torch.argmax(outputs, dim=-1).cpu().numpy()\n","            all_preds.extend(preds.flatten())\n","            all_labels.extend(labels.cpu().numpy().flatten())\n","\n","    return total_loss / len(dataloader), all_preds, all_labels\n","\n","# Training loop\n","epochs = 10\n","for epoch in range(epochs):\n","    train_loss = train(model, train_dataloader, optimizer, criterion, device)\n","    val_loss, val_preds, val_labels = evaluate(model, test_dataloader, criterion, device)\n","\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","    print(classification_report(val_labels, val_preds, target_names=['O', 'B-BEFORE', 'I-BEFORE', 'B-AFTER', 'I-AFTER', 'B-OVERLAP', 'I-OVERLAP']))\n","\n","# Output an example of evaluation\n","sample_input = test_tokens[0]\n","sample_pos = test_pos[0]\n","sample_labels = test_labels[0]\n","\n","model.eval()\n","with torch.no_grad():\n","    input_ids = torch.tensor(sample_input).unsqueeze(0).to(device)\n","    pos_encodings = torch.tensor(sample_pos).unsqueeze(0).to(device)\n","    outputs = model(input_ids, pos_encodings)\n","    preds = torch.argmax(outputs, dim=-1).cpu().numpy().flatten()\n","\n","print(\"Sample tokens:\", tokenizer.convert_ids_to_tokens(sample_input))\n","print(\"Sample true labels:\", sample_labels)\n","print(\"Sample predictions:\", preds)"]},{"cell_type":"markdown","metadata":{"id":"MEZBZUZm0cLf"},"source":["bert: tokens +{treatmeng postional one-hot} -> classifier"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"BRnpjqbo0Ikt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724660399744,"user_tz":-480,"elapsed":2666723,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"}},"outputId":"f9a5bdaa-aa4e-447d-d3fe-f53d336a485b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","Train Loss: 0.0713\n","Validation Loss: 0.0235\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.58      0.75      0.65     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.23      0.25      0.24   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 2/10\n","Train Loss: 0.0222\n","Validation Loss: 0.0198\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.70      0.74      0.72      2722\n","    I-BEFORE       0.70      0.75      0.72     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.34      0.35      0.35   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 3/10\n","Train Loss: 0.0195\n","Validation Loss: 0.0192\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.69      0.75      0.72      2722\n","    I-BEFORE       0.70      0.75      0.72     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.34      0.36      0.35   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 4/10\n","Train Loss: 0.0185\n","Validation Loss: 0.0193\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.70      0.71      0.71      2722\n","    I-BEFORE       0.70      0.74      0.72     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.34      0.35      0.35   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 5/10\n","Train Loss: 0.0182\n","Validation Loss: 0.0193\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.69      0.70      0.70      2722\n","    I-BEFORE       0.70      0.67      0.69     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.34      0.34      0.34   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 6/10\n","Train Loss: 0.0172\n","Validation Loss: 0.0194\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.68      0.76      0.72      2722\n","    I-BEFORE       0.70      0.75      0.72     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.34      0.36      0.35   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 7/10\n","Train Loss: 0.0164\n","Validation Loss: 0.0190\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.65      0.75      0.70      2722\n","    I-BEFORE       0.68      0.75      0.71     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.33      0.36      0.34   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 8/10\n","Train Loss: 0.0151\n","Validation Loss: 0.0194\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.69      0.65      0.67      2722\n","    I-BEFORE       0.68      0.72      0.70     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.34      0.34      0.34   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 9/10\n","Train Loss: 0.0142\n","Validation Loss: 0.0189\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.65      0.74      0.70      2722\n","    I-BEFORE       0.67      0.75      0.71     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.33      0.36      0.34   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 10/10\n","Train Loss: 0.0134\n","Validation Loss: 0.0188\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.68      0.72      0.70      2722\n","    I-BEFORE       0.69      0.73      0.71     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.34      0.35      0.34   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Sample tokens: ['admission', 'date', ':', '2014', '-', '11', '-', '29', 'discharge', 'date', ':', '2014', '-', '12', '-', '05', 'service', ':', 'medicine', 'history', 'of', 'present', 'illness', ':', '47', 'yo', 'f', 'w', '/', 'h', '/', 'o', 'ste', '##roid', '-', 'induced', 'hyper', '##gly', '##ce', '##mia', ',', 'sl', '##e', 'w', '/', 'h', '/', 'o', 'per', '##ica', '##rdi', '##tis', ',', 'transverse', 'my', '##eli', '##tis', 'w', '/', 'para', '##ple', '##gia', 'and', 'ne', '##uro', '##genic', 'bladder', 's', '/', 'p', 'ur', '##ost', '##omy', 'w', '/', 'ile', '##al', 'con', '##du', '##it', ',', 'h', '/', 'o', 'ur', '##eter', '##ope', '##l', '##vic', 'stone', 'and', 'ur', '##ose', '##psis', ',', 'and', 'h', '/', 'o', 'r', '##le', 'd', '##v', '##t', 'a', '/', 'w', 'f', '2014', '-', '11', '-', '29', 'transferred', 'to', 'cm', '##ed', '2014', '-', '11', '-', '30', 'for', 'h', '##yp', '##ot', '##n', 'resistant', 'to', 'iv', '##fs', 'and', 'stress', 'ste', '##roids', '.', 'patient', 'initially', 'p', '/', 'w', 'c', '/', 'o', 'sudden', 'onset', 'n', '/', 'abd', 'pain', '/', 'chill', '##s', 'w', '/', 't', '103', 'at', 'nh', '.', 'rig', '##ors', 'progressed', 'so', 'she', 'was', 'brought', 'to', 'robert', '.', 'she', 'reported', 'h', '/', 'o', 'fatigue', 'and', 'an', '##ore', '##xia', 'for', 'the', 'past', 'few', 'days', 'and', 'had', 'noticed', 'foul', 'smelling', 'urine', 'and', 'some', 'abdominal', 'di', '##sten', '##sion', ',', 'similar', 'to', 'prior', 'episodes', 'of', 'p', '##ye', '##lo', '.', 'she', 'also', 'c', '/', 'o', 'll', '##q', 'and', 'groin', 'pain', 'which', 'responded', 'to', 'ty', '##len', '##ol', '.', 'she', 'denies', 'v', 'or', 'd', '.', 'no', 'am', '##s', '.', 'no', 'c', '/', 'o', 'cp', '.', 'on', 'arrival', 'to', 'shirley', ',', 'temperature', 'was', '101', '.', '2', '.', 'ct', 'abd', 'showed', 'an', '8', 'mm', 'right', 'pro', '##xi', '##mal', 'ur', '##eter', '##al', 'stone', 'with', 'right', '-', 'sided', 'hydro', '##ne', '##ph', '##rosis', 'and', 'inflammatory', 'strand', '##ing', ',', 'in', 'addition', 'to', 'p', '##ye', '##lone', '##ph', '##rit', '##is', 'of', 'the', 'left', 'kidney', 'without', 'left', 'sided', 'hydro', '##ne', '##ph', '##rosis', '.', 'labs', 'were', 'remarkable', 'for', 'wb', '##c', '23', '.', '5', 'w', '/', '1', '%', 'bands', 'which', 'decreased', 'to', '14', 'today', 'but', 'now', 'w', '/', '15', '%', 'bands', 'on', 'van', '##c', '(', 'h', '/', 'o', 'mrs', '##a', 'ur', '##ose', '##psis', ')', 'and', 'gen', '##t', '(', 'mu', '##lt', 'drug', 'all', '##er', '##gies', ')', '.', 'ag', 'on', 'admission', '18', '(', 'bi', '##car', '##b', '17', ',', 'down', 'from', '23', 'on', 'a', 'previous', 'admission', ')', ',', 'down', 'to', 'ag', '15', 'this', 'am', '.', 'ab', '##g', 'prior', 'to', 'transfer', '(', 'on', 'room', 'air', ')', ':', '7', '.', '43', '/', '24', '/', '69', 'w', '/', 'lac', '##tate', '1', '.', '3', '(', 'down', 'from', '1', '.', '4', 'on', 'the', 'prior', 'day', ')', '.', 'currently', ',', '03', '-', '14', 'blood', 'c', '##x', 'are', 'growing', 'g', '##nr', 'in', 'both', 'ana', '##ero', '##bic', 'bottles', '.', 'urine', 'c', '##x', 'is', 'pending', '.', 'prior', 'to', 'transfer', ',', 'patient', 'dropped', 'bp', 'to', '68', '/', '40', '##s', '.', 'bp', 'did', 'not', 'improve', 'despite', '2', 'l', 'ns', 'and', '100', 'mg', 'iv', 'hydro', '##cor', '##tis', '##one', '.', 'a', 'central', 'line', 'was', 'placed', 'and', 'she', 'was', 'sent', 'to', 'ir', 'for', 'a', 'right', 'ne', '##ph', '##ros', '##tom', '##y', 'tube', '.', 'brief', 'hospital', 'course', ':', '47', 'yo', 'f', 'w', '/', 'h', '/', 'o', 'ste', '##roid', '-', 'induced', 'hyper', '##gly', '##ce', '##mia', ',', 'sl', '##e']\n","Sample true labels: [0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Sample predictions: [0 0 0 0 0 0 0 0 0 0 0 1 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import BertModel, BertTokenizerFast\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import numpy as np\n","\n","# Define a custom dataset class\n","class SequenceLabelingDataset(Dataset):\n","    def __init__(self, tokens, pos_encodings, labels):\n","        self.tokens = tokens\n","        self.pos_encodings = pos_encodings\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.tokens)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.tokens[idx],\n","            'pos_encodings': self.pos_encodings[idx],\n","            'labels': self.labels[idx]}\n","\n","# Custom collate function to pad sequences\n","def collate_fn(batch):\n","    max_len = max([len(x['input_ids']) for x in batch])\n","\n","    input_ids = []\n","    pos_encodings = []\n","    labels = []\n","\n","    for item in batch:\n","        input_ids.append(item['input_ids'] + [0] * (max_len - len(item['input_ids'])))\n","        pos_encodings.append(item['pos_encodings'] + [0] * (max_len - len(item['pos_encodings'])))\n","        labels.append(item['labels'] + [0] * (max_len - len(item['labels'])))\n","\n","    return {\n","        'input_ids': torch.tensor(input_ids, dtype=torch.long),\n","        'pos_encodings': torch.tensor(pos_encodings, dtype=torch.float),\n","        'labels': torch.tensor(labels, dtype=torch.long)\n","    }\n","\n","# Prepare the data\n","def prepare_data(alignment_annotations, tokenizer, max_len=512):\n","    label_to_id = {\n","        \"O\": 0,\n","        \"B-BEFORE\": 1,\n","        \"I-BEFORE\": 2,\n","        \"B-AFTER\": 3,\n","        \"I-AFTER\": 4,\n","        \"B-OVERLAP\": 5,\n","        \"I-OVERLAP\": 6\n","    }\n","\n","    tokens, pos_encodings, labels = [], [], []\n","\n","    for entry in alignment_annotations:\n","        token_ids = tokenizer.convert_tokens_to_ids(entry['tokens'])\n","        pos_encoding = [1 if tag == \"B-TREATMENT\" or tag == \"I-TREATMENT\" else 0 for tag in entry['bio_treatment_aligned']]\n","        label = [label_to_id.get(tag, 0) for tag in entry['bio_time_aligned']]  # default to 0 if tag not found\n","\n","        if len(token_ids) > max_len:\n","            token_ids = token_ids[:max_len]\n","            pos_encoding = pos_encoding[:max_len]\n","            label = label[:max_len]\n","\n","        tokens.append(token_ids)\n","        pos_encodings.append(pos_encoding)\n","        labels.append(label)\n","\n","    return tokens, pos_encodings, labels\n","\n","# Load data and prepare datasets\n","# tokens, pos_encodings, labels = prepare_data(alignment_annotations, tokenizer)\n","\n","# Split data into training and test sets\n","# train_tokens, test_tokens, train_pos, test_pos, train_labels, test_labels = train_test_split(\n","#     tokens, pos_encodings, labels, test_size=0.2, random_state=42\n","# )\n","\n","test_tokens, test_pos, test_labels = prepare_data(alignment_annotations, tokenizer)\n","train_tokens, train_pos, train_labels = prepare_data(processed_data, tokenizer)\n","\n","\n","train_dataset = SequenceLabelingDataset(train_tokens, train_pos, train_labels)\n","test_dataset = SequenceLabelingDataset(test_tokens, test_pos, test_labels)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n","test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n","\n","# Define the BERT model with additional input for positional encoding\n","class BertForSequenceLabeling(nn.Module):\n","    def __init__(self, num_labels=7):\n","        super(BertForSequenceLabeling, self).__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","        self.dropout = nn.Dropout(0.3)\n","        self.classifier = nn.Linear(self.bert.config.hidden_size + 1, num_labels)\n","\n","    def forward(self, input_ids, pos_encodings):\n","        outputs = self.bert(input_ids)\n","        sequence_output = outputs.last_hidden_state\n","        # sequence_output torch.Size([16, 512, 768])\n","        # pos_encodings torch.Size([16, 512])\n","        # Concatenate positional encoding\n","\n","        pos_encodings = pos_encodings.unsqueeze(-1)\n","        # pos_encodings.unsqueeze(-1) torch.Size([16, 512, 1])\n","        sequence_output = torch.cat((sequence_output, pos_encodings), dim=-1)\n","        # torch.cat torch.Size([16, 512, 769])\n","\n","        sequence_output = self.dropout(sequence_output)\n","        logits = self.classifier(sequence_output)\n","\n","        return logits\n","\n","# Initialize the model\n","model = BertForSequenceLabeling(num_labels=7)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n","\n","# Training function\n","def train(model, dataloader, optimizer, criterion, device):\n","    model.train()\n","    total_loss = 0\n","    for batch in dataloader:\n","        input_ids = batch['input_ids'].to(device)\n","        pos_encodings = batch['pos_encodings'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, pos_encodings)\n","        loss = criterion(outputs.view(-1, 7), labels.view(-1))\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","    return total_loss / len(dataloader)\n","\n","# Evaluation function\n","def evaluate(model, dataloader, criterion, device):\n","    model.eval()\n","    total_loss = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            input_ids = batch['input_ids'].to(device)\n","            pos_encodings = batch['pos_encodings'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids, pos_encodings)\n","            loss = criterion(outputs.view(-1, 7), labels.view(-1))\n","\n","            total_loss += loss.item()\n","\n","            preds = torch.argmax(outputs, dim=-1).cpu().numpy()\n","            all_preds.extend(preds.flatten())\n","            all_labels.extend(labels.cpu().numpy().flatten())\n","\n","    return total_loss / len(dataloader), all_preds, all_labels\n","\n","# Training loop\n","epochs = 10\n","for epoch in range(epochs):\n","    train_loss = train(model, train_dataloader, optimizer, criterion, device)\n","    val_loss, val_preds, val_labels = evaluate(model, test_dataloader, criterion, device)\n","\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","    print(classification_report(val_labels, val_preds, target_names=['O', 'B-BEFORE', 'I-BEFORE', 'B-AFTER', 'I-AFTER', 'B-OVERLAP', 'I-OVERLAP']))\n","\n","# Output an example of evaluation\n","sample_input = test_tokens[0]\n","sample_pos = test_pos[0]\n","sample_labels = test_labels[0]\n","\n","model.eval()\n","with torch.no_grad():\n","    input_ids = torch.tensor(sample_input).unsqueeze(0).to(device)\n","    pos_encodings = torch.tensor(sample_pos).unsqueeze(0).to(device)\n","    outputs = model(input_ids, pos_encodings)\n","    preds = torch.argmax(outputs, dim=-1).cpu().numpy().flatten()\n","\n","print(\"Sample tokens:\", tokenizer.convert_ids_to_tokens(sample_input))\n","print(\"Sample true labels:\", sample_labels)\n","print(\"Sample predictions:\", preds)"]},{"cell_type":"markdown","metadata":{"id":"bbVV7g-31DBu"},"source":["bert: tokens +{treatmeng postional one-hot} -> 4FCN + classifier"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2668254,"status":"ok","timestamp":1724663067993,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":-480},"id":"4t3N7pDJ0Ihn","outputId":"03c4c34f-c281-4da0-c578-2a4e2eb7f120"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","Train Loss: 0.9490\n","Validation Loss: 0.0818\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       0.99      1.00      0.99   1507295\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.00      0.00      0.00     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.14      0.14      0.14   1522512\n","weighted avg       0.98      0.99      0.99   1522512\n","\n","Epoch 2/10\n","Train Loss: 0.0655\n","Validation Loss: 0.0429\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       0.99      1.00      0.99   1507295\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.00      0.00      0.00     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.14      0.14      0.14   1522512\n","weighted avg       0.98      0.99      0.99   1522512\n","\n","Epoch 3/10\n","Train Loss: 0.0375\n","Validation Loss: 0.0322\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       0.99      1.00      0.99   1507295\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.00      0.00      0.00     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.14      0.14      0.14   1522512\n","weighted avg       0.98      0.99      0.99   1522512\n","\n","Epoch 4/10\n","Train Loss: 0.0307\n","Validation Loss: 0.0264\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.56      0.75      0.64     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.22      0.25      0.23   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 5/10\n","Train Loss: 0.0260\n","Validation Loss: 0.0246\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.56      0.75      0.64     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.22      0.25      0.23   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 6/10\n","Train Loss: 0.0246\n","Validation Loss: 0.0240\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.56      0.74      0.64     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.22      0.25      0.23   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 7/10\n","Train Loss: 0.0244\n","Validation Loss: 0.0236\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.56      0.75      0.64     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.22      0.25      0.23   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 8/10\n","Train Loss: 0.0239\n","Validation Loss: 0.0235\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.56      0.75      0.64     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.22      0.25      0.23   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 9/10\n","Train Loss: 0.0237\n","Validation Loss: 0.0236\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.56      0.73      0.64     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.22      0.25      0.23   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Epoch 10/10\n","Train Loss: 0.0232\n","Validation Loss: 0.0240\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1507295\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.56      0.75      0.64     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1522512\n","   macro avg       0.22      0.25      0.23   1522512\n","weighted avg       0.99      0.99      0.99   1522512\n","\n","Sample tokens: ['admission', 'date', ':', '2014', '-', '11', '-', '29', 'discharge', 'date', ':', '2014', '-', '12', '-', '05', 'service', ':', 'medicine', 'history', 'of', 'present', 'illness', ':', '47', 'yo', 'f', 'w', '/', 'h', '/', 'o', 'ste', '##roid', '-', 'induced', 'hyper', '##gly', '##ce', '##mia', ',', 'sl', '##e', 'w', '/', 'h', '/', 'o', 'per', '##ica', '##rdi', '##tis', ',', 'transverse', 'my', '##eli', '##tis', 'w', '/', 'para', '##ple', '##gia', 'and', 'ne', '##uro', '##genic', 'bladder', 's', '/', 'p', 'ur', '##ost', '##omy', 'w', '/', 'ile', '##al', 'con', '##du', '##it', ',', 'h', '/', 'o', 'ur', '##eter', '##ope', '##l', '##vic', 'stone', 'and', 'ur', '##ose', '##psis', ',', 'and', 'h', '/', 'o', 'r', '##le', 'd', '##v', '##t', 'a', '/', 'w', 'f', '2014', '-', '11', '-', '29', 'transferred', 'to', 'cm', '##ed', '2014', '-', '11', '-', '30', 'for', 'h', '##yp', '##ot', '##n', 'resistant', 'to', 'iv', '##fs', 'and', 'stress', 'ste', '##roids', '.', 'patient', 'initially', 'p', '/', 'w', 'c', '/', 'o', 'sudden', 'onset', 'n', '/', 'abd', 'pain', '/', 'chill', '##s', 'w', '/', 't', '103', 'at', 'nh', '.', 'rig', '##ors', 'progressed', 'so', 'she', 'was', 'brought', 'to', 'robert', '.', 'she', 'reported', 'h', '/', 'o', 'fatigue', 'and', 'an', '##ore', '##xia', 'for', 'the', 'past', 'few', 'days', 'and', 'had', 'noticed', 'foul', 'smelling', 'urine', 'and', 'some', 'abdominal', 'di', '##sten', '##sion', ',', 'similar', 'to', 'prior', 'episodes', 'of', 'p', '##ye', '##lo', '.', 'she', 'also', 'c', '/', 'o', 'll', '##q', 'and', 'groin', 'pain', 'which', 'responded', 'to', 'ty', '##len', '##ol', '.', 'she', 'denies', 'v', 'or', 'd', '.', 'no', 'am', '##s', '.', 'no', 'c', '/', 'o', 'cp', '.', 'on', 'arrival', 'to', 'shirley', ',', 'temperature', 'was', '101', '.', '2', '.', 'ct', 'abd', 'showed', 'an', '8', 'mm', 'right', 'pro', '##xi', '##mal', 'ur', '##eter', '##al', 'stone', 'with', 'right', '-', 'sided', 'hydro', '##ne', '##ph', '##rosis', 'and', 'inflammatory', 'strand', '##ing', ',', 'in', 'addition', 'to', 'p', '##ye', '##lone', '##ph', '##rit', '##is', 'of', 'the', 'left', 'kidney', 'without', 'left', 'sided', 'hydro', '##ne', '##ph', '##rosis', '.', 'labs', 'were', 'remarkable', 'for', 'wb', '##c', '23', '.', '5', 'w', '/', '1', '%', 'bands', 'which', 'decreased', 'to', '14', 'today', 'but', 'now', 'w', '/', '15', '%', 'bands', 'on', 'van', '##c', '(', 'h', '/', 'o', 'mrs', '##a', 'ur', '##ose', '##psis', ')', 'and', 'gen', '##t', '(', 'mu', '##lt', 'drug', 'all', '##er', '##gies', ')', '.', 'ag', 'on', 'admission', '18', '(', 'bi', '##car', '##b', '17', ',', 'down', 'from', '23', 'on', 'a', 'previous', 'admission', ')', ',', 'down', 'to', 'ag', '15', 'this', 'am', '.', 'ab', '##g', 'prior', 'to', 'transfer', '(', 'on', 'room', 'air', ')', ':', '7', '.', '43', '/', '24', '/', '69', 'w', '/', 'lac', '##tate', '1', '.', '3', '(', 'down', 'from', '1', '.', '4', 'on', 'the', 'prior', 'day', ')', '.', 'currently', ',', '03', '-', '14', 'blood', 'c', '##x', 'are', 'growing', 'g', '##nr', 'in', 'both', 'ana', '##ero', '##bic', 'bottles', '.', 'urine', 'c', '##x', 'is', 'pending', '.', 'prior', 'to', 'transfer', ',', 'patient', 'dropped', 'bp', 'to', '68', '/', '40', '##s', '.', 'bp', 'did', 'not', 'improve', 'despite', '2', 'l', 'ns', 'and', '100', 'mg', 'iv', 'hydro', '##cor', '##tis', '##one', '.', 'a', 'central', 'line', 'was', 'placed', 'and', 'she', 'was', 'sent', 'to', 'ir', 'for', 'a', 'right', 'ne', '##ph', '##ros', '##tom', '##y', 'tube', '.', 'brief', 'hospital', 'course', ':', '47', 'yo', 'f', 'w', '/', 'h', '/', 'o', 'ste', '##roid', '-', 'induced', 'hyper', '##gly', '##ce', '##mia', ',', 'sl', '##e']\n","Sample true labels: [0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Sample predictions: [0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"," 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["# Define a custom dataset class\n","class SequenceLabelingDataset(Dataset):\n","    def __init__(self, tokens, pos_encodings, labels):\n","        self.tokens = tokens\n","        self.pos_encodings = pos_encodings\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.tokens)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.tokens[idx],\n","            'pos_encodings': self.pos_encodings[idx],\n","            'labels': self.labels[idx]}\n","\n","# Custom collate function to pad sequences\n","def collate_fn(batch):\n","    max_len = max([len(x['input_ids']) for x in batch])\n","\n","    input_ids = []\n","    pos_encodings = []\n","    labels = []\n","\n","    for item in batch:\n","        input_ids.append(item['input_ids'] + [0] * (max_len - len(item['input_ids'])))\n","        pos_encodings.append(item['pos_encodings'] + [0] * (max_len - len(item['pos_encodings'])))\n","        labels.append(item['labels'] + [0] * (max_len - len(item['labels'])))\n","\n","    return {\n","        'input_ids': torch.tensor(input_ids, dtype=torch.long),\n","        'pos_encodings': torch.tensor(pos_encodings, dtype=torch.float),\n","        'labels': torch.tensor(labels, dtype=torch.long)\n","    }\n","\n","# Prepare the data\n","def prepare_data(alignment_annotations, tokenizer, max_len=512):\n","    label_to_id = {\n","        \"O\": 0,\n","        \"B-BEFORE\": 1,\n","        \"I-BEFORE\": 2,\n","        \"B-AFTER\": 3,\n","        \"I-AFTER\": 4,\n","        \"B-OVERLAP\": 5,\n","        \"I-OVERLAP\": 6\n","    }\n","\n","    tokens, pos_encodings, labels = [], [], []\n","\n","    for entry in alignment_annotations:\n","        token_ids = tokenizer.convert_tokens_to_ids(entry['tokens'])\n","        pos_encoding = [1 if tag == \"B-TREATMENT\" or tag == \"I-TREATMENT\" else 0 for tag in entry['bio_treatment_aligned']]\n","        label = [label_to_id.get(tag, 0) for tag in entry['bio_time_aligned']]  # default to 0 if tag not found\n","\n","        if len(token_ids) > max_len:\n","            token_ids = token_ids[:max_len]\n","            pos_encoding = pos_encoding[:max_len]\n","            label = label[:max_len]\n","\n","        tokens.append(token_ids)\n","        pos_encodings.append(pos_encoding)\n","        labels.append(label)\n","\n","    return tokens, pos_encodings, labels\n","\n","# Load data and prepare datasets\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","tokens, pos_encodings, labels = prepare_data(alignment_annotations, tokenizer)\n","\n","# Split data into training and test sets\n","# train_tokens, test_tokens, train_pos, test_pos, train_labels, test_labels = train_test_split(\n","#     tokens, pos_encodings, labels, test_size=0.2, random_state=42\n","# )\n","\n","test_tokens, test_pos, test_labels = prepare_data(alignment_annotations, tokenizer)\n","train_tokens, train_pos, train_labels = prepare_data(processed_data, tokenizer)\n","\n","\n","train_dataset = SequenceLabelingDataset(train_tokens, train_pos, train_labels)\n","test_dataset = SequenceLabelingDataset(test_tokens, test_pos, test_labels)\n","\n","\n","# Compute sample weights\n","label_counts = np.bincount([label for sublist in train_labels for label in sublist])\n","class_weights = 1. / label_counts\n","sample_weights = []\n","for label_list in train_labels:\n","    for label in label_list:\n","        sample_weights.append(class_weights[label])\n","\n","# sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n","\n","# Create dataloaders with sampler\n","# train_dataloader = DataLoader(train_dataset, batch_size=16, sampler=sampler, collate_fn=collate_fn)\n","# test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n","\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n","test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n","\n","# Define the BERT model with additional input for positional encoding and FC layers\n","class BertForSequenceLabeling(nn.Module):\n","    def __init__(self, num_labels=7):\n","        super(BertForSequenceLabeling, self).__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(self.bert.config.hidden_size + 1, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 128)\n","        self.fc4 = nn.Linear(128, 64)\n","        self.classifier = nn.Linear(64, num_labels)\n","\n","    def forward(self, input_ids, pos_encodings):\n","        outputs = self.bert(input_ids)\n","        sequence_output = outputs.last_hidden_state\n","        pos_encodings = pos_encodings.unsqueeze(-1)\n","        sequence_output = torch.cat((sequence_output, pos_encodings), dim=-1)\n","\n","        sequence_output = self.dropout(sequence_output)\n","        sequence_output = torch.relu(self.fc1(sequence_output))\n","        sequence_output = torch.relu(self.fc2(sequence_output))\n","        sequence_output = torch.relu(self.fc3(sequence_output))\n","        sequence_output = torch.relu(self.fc4(sequence_output))\n","        logits = self.classifier(sequence_output)\n","\n","        return logits\n","\n","# Initialize the model\n","model = BertForSequenceLabeling(num_labels=7)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n","\n","# Training function\n","def train(model, dataloader, optimizer, criterion, device):\n","    model.train()\n","    total_loss = 0\n","    for batch in dataloader:\n","        input_ids = batch['input_ids'].to(device)\n","        pos_encodings = batch['pos_encodings'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(input_ids, pos_encodings)\n","        loss = criterion(outputs.view(-1, 7), labels.view(-1))\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","    return total_loss / len(dataloader)\n","\n","# Evaluation function\n","def evaluate(model, dataloader, criterion, device):\n","    model.eval()\n","    total_loss = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            input_ids = batch['input_ids'].to(device)\n","            pos_encodings = batch['pos_encodings'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids, pos_encodings)\n","            loss = criterion(outputs.view(-1, 7), labels.view(-1))\n","\n","            total_loss += loss.item()\n","\n","            preds = torch.argmax(outputs, dim=-1).cpu().numpy()\n","            all_preds.extend(preds.flatten())\n","            all_labels.extend(labels.cpu().numpy().flatten())\n","\n","    return total_loss / len(dataloader), all_preds, all_labels\n","\n","# Training loop\n","epochs = 10\n","for epoch in range(epochs):\n","    train_loss = train(model, train_dataloader, optimizer, criterion, device)\n","    val_loss, val_preds, val_labels = evaluate(model, test_dataloader, criterion, device)\n","\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","    print(classification_report(val_labels, val_preds, target_names=['O', 'B-BEFORE', 'I-BEFORE', 'B-AFTER', 'I-AFTER', 'B-OVERLAP', 'I-OVERLAP']))\n","\n","# Output an example of evaluation\n","sample_input = test_tokens[0]\n","sample_pos = test_pos[0]\n","sample_labels = test_labels[0]\n","\n","model.eval()\n","with torch.no_grad():\n","    input_ids = torch.tensor(sample_input).unsqueeze(0).to(device)\n","    pos_encodings = torch.tensor(sample_pos).unsqueeze(0).to(device)\n","    outputs = model(input_ids, pos_encodings)\n","    preds = torch.argmax(outputs, dim=-1).cpu().numpy().flatten()\n","\n","print(\"Sample tokens:\", tokenizer.convert_ids_to_tokens(sample_input))\n","print(\"Sample true labels:\", sample_labels)\n","print(\"Sample predictions:\", preds)"]},{"cell_type":"markdown","metadata":{"id":"e8jfvHpq1Rnq"},"source":["bert: tokens +{treatmeng postional one-hot} -> CRF"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4618735,"status":"ok","timestamp":1724667688272,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":-480},"id":"V-Ipt-2p0IdR","outputId":"08d76592-0251-4a8f-c135-72eb15996e87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-crf\n","  Downloading pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\n","Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n","Installing collected packages: pytorch-crf\n","Successfully installed pytorch-crf-0.7.2\n","Epoch 1/10\n","Train Loss: 675.1723\n","Validation Loss: 195.6593\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1474343\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.56      0.75      0.64     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1489560\n","   macro avg       0.22      0.25      0.23   1489560\n","weighted avg       0.99      0.99      0.99   1489560\n","\n","Epoch 2/10\n","Train Loss: 202.1845\n","Validation Loss: 199.1550\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1474343\n","    B-BEFORE       0.00      0.00      0.00      2722\n","    I-BEFORE       0.56      0.75      0.64     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1489560\n","   macro avg       0.22      0.25      0.23   1489560\n","weighted avg       0.99      0.99      0.99   1489560\n","\n","Epoch 3/10\n","Train Loss: 178.1308\n","Validation Loss: 170.4568\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1474343\n","    B-BEFORE       0.66      0.80      0.72      2722\n","    I-BEFORE       0.59      0.85      0.69     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1489560\n","   macro avg       0.32      0.38      0.34   1489560\n","weighted avg       0.99      0.99      0.99   1489560\n","\n","Epoch 4/10\n","Train Loss: 159.7342\n","Validation Loss: 158.9218\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1474343\n","    B-BEFORE       0.67      0.78      0.72      2722\n","    I-BEFORE       0.70      0.75      0.73     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1489560\n","   macro avg       0.34      0.36      0.35   1489560\n","weighted avg       0.99      0.99      0.99   1489560\n","\n","Epoch 5/10\n","Train Loss: 153.7757\n","Validation Loss: 156.4159\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1474343\n","    B-BEFORE       0.64      0.82      0.72      2722\n","    I-BEFORE       0.70      0.75      0.72     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1489560\n","   macro avg       0.33      0.37      0.35   1489560\n","weighted avg       0.99      0.99      0.99   1489560\n","\n","Epoch 6/10\n","Train Loss: 152.1240\n","Validation Loss: 173.6645\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1474343\n","    B-BEFORE       0.70      0.74      0.72      2722\n","    I-BEFORE       0.69      0.76      0.72     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1489560\n","   macro avg       0.34      0.36      0.35   1489560\n","weighted avg       0.99      0.99      0.99   1489560\n","\n","Epoch 7/10\n","Train Loss: 145.3716\n","Validation Loss: 160.0598\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1474343\n","    B-BEFORE       0.69      0.55      0.61      2722\n","    I-BEFORE       0.71      0.56      0.63     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1489560\n","   macro avg       0.34      0.30      0.32   1489560\n","weighted avg       0.99      0.99      0.99   1489560\n","\n","Epoch 8/10\n","Train Loss: 139.0273\n","Validation Loss: 160.6238\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1474343\n","    B-BEFORE       0.67      0.77      0.71      2722\n","    I-BEFORE       0.69      0.75      0.72     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1489560\n","   macro avg       0.34      0.36      0.35   1489560\n","weighted avg       0.99      0.99      0.99   1489560\n","\n","Epoch 9/10\n","Train Loss: 133.8508\n","Validation Loss: 200.7482\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       0.99      1.00      1.00   1474343\n","    B-BEFORE       0.50      0.59      0.54      2722\n","    I-BEFORE       0.48      0.47      0.48     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1489560\n","   macro avg       0.28      0.29      0.29   1489560\n","weighted avg       0.99      0.99      0.99   1489560\n","\n","Epoch 10/10\n","Train Loss: 129.2791\n","Validation Loss: 198.2737\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           O       1.00      1.00      1.00   1474343\n","    B-BEFORE       0.56      0.56      0.56      2722\n","    I-BEFORE       0.57      0.66      0.61     10762\n","     B-AFTER       0.00      0.00      0.00       224\n","     I-AFTER       0.00      0.00      0.00       856\n","   B-OVERLAP       0.00      0.00      0.00       163\n","   I-OVERLAP       0.00      0.00      0.00       490\n","\n","    accuracy                           0.99   1489560\n","   macro avg       0.30      0.32      0.31   1489560\n","weighted avg       0.99      0.99      0.99   1489560\n","\n","Sample tokens: ['admission', 'date', ':', '2014', '-', '11', '-', '29', 'discharge', 'date', ':', '2014', '-', '12', '-', '05', 'service', ':', 'medicine', 'history', 'of', 'present', 'illness', ':', '47', 'yo', 'f', 'w', '/', 'h', '/', 'o', 'ste', '##roid', '-', 'induced', 'hyper', '##gly', '##ce', '##mia', ',', 'sl', '##e', 'w', '/', 'h', '/', 'o', 'per', '##ica', '##rdi', '##tis', ',', 'transverse', 'my', '##eli', '##tis', 'w', '/', 'para', '##ple', '##gia', 'and', 'ne', '##uro', '##genic', 'bladder', 's', '/', 'p', 'ur', '##ost', '##omy', 'w', '/', 'ile', '##al', 'con', '##du', '##it', ',', 'h', '/', 'o', 'ur', '##eter', '##ope', '##l', '##vic', 'stone', 'and', 'ur', '##ose', '##psis', ',', 'and', 'h', '/', 'o', 'r', '##le', 'd', '##v', '##t', 'a', '/', 'w', 'f', '2014', '-', '11', '-', '29', 'transferred', 'to', 'cm', '##ed', '2014', '-', '11', '-', '30', 'for', 'h', '##yp', '##ot', '##n', 'resistant', 'to', 'iv', '##fs', 'and', 'stress', 'ste', '##roids', '.', 'patient', 'initially', 'p', '/', 'w', 'c', '/', 'o', 'sudden', 'onset', 'n', '/', 'abd', 'pain', '/', 'chill', '##s', 'w', '/', 't', '103', 'at', 'nh', '.', 'rig', '##ors', 'progressed', 'so', 'she', 'was', 'brought', 'to', 'robert', '.', 'she', 'reported', 'h', '/', 'o', 'fatigue', 'and', 'an', '##ore', '##xia', 'for', 'the', 'past', 'few', 'days', 'and', 'had', 'noticed', 'foul', 'smelling', 'urine', 'and', 'some', 'abdominal', 'di', '##sten', '##sion', ',', 'similar', 'to', 'prior', 'episodes', 'of', 'p', '##ye', '##lo', '.', 'she', 'also', 'c', '/', 'o', 'll', '##q', 'and', 'groin', 'pain', 'which', 'responded', 'to', 'ty', '##len', '##ol', '.', 'she', 'denies', 'v', 'or', 'd', '.', 'no', 'am', '##s', '.', 'no', 'c', '/', 'o', 'cp', '.', 'on', 'arrival', 'to', 'shirley', ',', 'temperature', 'was', '101', '.', '2', '.', 'ct', 'abd', 'showed', 'an', '8', 'mm', 'right', 'pro', '##xi', '##mal', 'ur', '##eter', '##al', 'stone', 'with', 'right', '-', 'sided', 'hydro', '##ne', '##ph', '##rosis', 'and', 'inflammatory', 'strand', '##ing', ',', 'in', 'addition', 'to', 'p', '##ye', '##lone', '##ph', '##rit', '##is', 'of', 'the', 'left', 'kidney', 'without', 'left', 'sided', 'hydro', '##ne', '##ph', '##rosis', '.', 'labs', 'were', 'remarkable', 'for', 'wb', '##c', '23', '.', '5', 'w', '/', '1', '%', 'bands', 'which', 'decreased', 'to', '14', 'today', 'but', 'now', 'w', '/', '15', '%', 'bands', 'on', 'van', '##c', '(', 'h', '/', 'o', 'mrs', '##a', 'ur', '##ose', '##psis', ')', 'and', 'gen', '##t', '(', 'mu', '##lt', 'drug', 'all', '##er', '##gies', ')', '.', 'ag', 'on', 'admission', '18', '(', 'bi', '##car', '##b', '17', ',', 'down', 'from', '23', 'on', 'a', 'previous', 'admission', ')', ',', 'down', 'to', 'ag', '15', 'this', 'am', '.', 'ab', '##g', 'prior', 'to', 'transfer', '(', 'on', 'room', 'air', ')', ':', '7', '.', '43', '/', '24', '/', '69', 'w', '/', 'lac', '##tate', '1', '.', '3', '(', 'down', 'from', '1', '.', '4', 'on', 'the', 'prior', 'day', ')', '.', 'currently', ',', '03', '-', '14', 'blood', 'c', '##x', 'are', 'growing', 'g', '##nr', 'in', 'both', 'ana', '##ero', '##bic', 'bottles', '.', 'urine', 'c', '##x', 'is', 'pending', '.', 'prior', 'to', 'transfer', ',', 'patient', 'dropped', 'bp', 'to', '68', '/', '40', '##s', '.', 'bp', 'did', 'not', 'improve', 'despite', '2', 'l', 'ns', 'and', '100', 'mg', 'iv', 'hydro', '##cor', '##tis', '##one', '.', 'a', 'central', 'line', 'was', 'placed', 'and', 'she', 'was', 'sent', 'to', 'ir', 'for', 'a', 'right', 'ne', '##ph', '##ros', '##tom', '##y', 'tube', '.', 'brief', 'hospital', 'course', ':', '47', 'yo', 'f', 'w', '/', 'h', '/', 'o', 'ste', '##roid', '-', 'induced', 'hyper', '##gly', '##ce', '##mia', ',', 'sl', '##e']\n","Sample true labels: [0, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Sample predictions: [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["!pip install pytorch-crf\n","from torchcrf import CRF\n","\n","class BertForSequenceLabeling(nn.Module):\n","    def __init__(self, num_labels=7):\n","        super(BertForSequenceLabeling, self).__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","        self.dropout = nn.Dropout(0.3)\n","        self.classifier = nn.Linear(self.bert.config.hidden_size + 1, num_labels)\n","        self.crf = CRF(num_labels, batch_first=True)\n","\n","    def forward(self, input_ids, pos_encodings, labels=None):\n","        outputs = self.bert(input_ids)\n","        sequence_output = outputs.last_hidden_state\n","\n","        pos_encodings = pos_encodings.unsqueeze(-1)\n","        sequence_output = torch.cat((sequence_output, pos_encodings), dim=-1)\n","\n","        sequence_output = self.dropout(sequence_output)\n","        logits = self.classifier(sequence_output)\n","\n","        if labels is not None:\n","            loss = -self.crf(logits, labels, mask=input_ids.ne(0))\n","            return loss\n","        else:\n","            predictions = self.crf.decode(logits, mask=input_ids.ne(0))\n","            return predictions\n","\n","# Initialize the model\n","model = BertForSequenceLabeling(num_labels=7)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Define optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n","\n","# Training function\n","def train(model, dataloader, optimizer, device):\n","    model.train()\n","    total_loss = 0\n","    for batch in dataloader:\n","        input_ids = batch['input_ids'].to(device)\n","        pos_encodings = batch['pos_encodings'].to(device)\n","        labels = batch['labels'].to(device)\n","\n","        optimizer.zero_grad()\n","        loss = model(input_ids, pos_encodings, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","    return total_loss / len(dataloader)\n","\n","# Evaluation function\n","def evaluate(model, dataloader, device):\n","    model.eval()\n","    total_loss = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for batch in dataloader:\n","            input_ids = batch['input_ids'].to(device)\n","            pos_encodings = batch['pos_encodings'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            loss = model(input_ids, pos_encodings, labels)\n","            total_loss += loss.item()\n","\n","            predictions = model(input_ids, pos_encodings)\n","\n","            input_mask = input_ids.ne(0)  # Mask to identify non-padding tokens\n","\n","            for pred, label, mask in zip(predictions, labels.cpu().numpy(), input_mask.cpu().numpy()):\n","                filtered_pred = [p for p, m in zip(pred, mask) if m]\n","                filtered_label = [l for l, m in zip(label, mask) if m]\n","\n","                all_preds.extend(filtered_pred)\n","                all_labels.extend(filtered_label)\n","\n","    return total_loss / len(dataloader), all_preds, all_labels\n","\n","# Training loop\n","epochs = 10\n","for epoch in range(epochs):\n","    train_loss = train(model, train_dataloader, optimizer, device)\n","    val_loss, val_preds, val_labels = evaluate(model, test_dataloader, device)\n","\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","    print(f\"Train Loss: {train_loss:.4f}\")\n","    print(f\"Validation Loss: {val_loss:.4f}\")\n","\n","    print(classification_report(val_labels, val_preds, target_names=['O', 'B-BEFORE', 'I-BEFORE', 'B-AFTER', 'I-AFTER', 'B-OVERLAP', 'I-OVERLAP']))\n","\n","# Output an example of evaluation\n","sample_input = test_tokens[0]\n","sample_pos = test_pos[0]\n","sample_labels = test_labels[0]\n","\n","model.eval()\n","with torch.no_grad():\n","    input_ids = torch.tensor(sample_input).unsqueeze(0).to(device)\n","    pos_encodings = torch.tensor(sample_pos).unsqueeze(0).to(device)\n","    predictions = model(input_ids, pos_encodings)\n","\n","print(\"Sample tokens:\", tokenizer.convert_ids_to_tokens(sample_input))\n","print(\"Sample true labels:\", sample_labels)\n","print(\"Sample predictions:\", predictions)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":561,"referenced_widgets":["9270e743d5164397aee9d789cfec3552","c93cee2f61b345ff89805903935a529f","26b1e12b225942fbb5ff4de9010d0354","3a60025b14f64381957be1c217423fa4","2e95635db0d6470c80ec6ea65d7d36e5","83fbc39fb80a4018a38fb690c18f74a2","a6bc9e4e36d544349037e96dd5af7107","e11c171dafda4021a28d04bb56e2b20b","e72a62f7f30c40d0bc6494d002195fad","db7aedf3e033448badef5441f44c7abc","664a67d58861483faf511c3c59debfff","988d23f9591d4bc4b8b0ca52626f29e6","3b1021234da94ba9858d97ff156bf7ef","970f149a42ff44a88ee4b3609eb546fc","5a93260155334b4c9dc8668a4a03f8c6","289c2df0c25b419c8a0a7f443644a5c4","e81923b77f3445919b91e6eef6f8655d","49a7b78653be4025a3ee72c529d667de","66f636bc78634fde9a44111c9c23a623","2e1662c993234a6a8f49ef0775c1de56","bb9c76e2981a462f82f3653036a6d806","5d606467ea8b49b8a4dfa033af378311","6dbe41eb88304205aa95ccf20d59e68c","822f539f794a4234805ffb2c94bd7cab","c0528d0a8b3f4257b9234a5f2f4a9139","4b8361118c064d3d9e144e5536cae365","ece30b0166514288bebf78a3a974c94b","142970585c764b549b84fa6c8932fe09","10bf8340787e4900bf47e598d1249009","9ee3693423a14d079b0f662ab13fd6a5","b3060e571dc841f9b4e0ccade2f24eb3","a32f0c4f300d4e68a39086bc4101a256","bafbc18d6e9b4142bd29d9c8f862f7a0","777b6e9e2c46476c85452489d88325be","c26c22823241416985216d331da7bde4","858f429a365d43a99d06b880c15f31cb","e1afbd4c06cb468683016b2706f7aa33","bcab38f43d2f49b0a7e87644fec743df","46247476258e4a64bba9ed619dd67366","d0864335a7734977a12975b3ca937008","8a755705a6fe4aa681505b55a8579062","bed9c2abe56e4b2994ebe9ce8ed97412","a851e45549c242b39347fda5b1f0ea17","7df4fff285194e94902a4768bd873383"]},"executionInfo":{"elapsed":12581,"status":"ok","timestamp":1724408372031,"user":{"displayName":"崔洋（Yang）","userId":"11100323723687542220"},"user_tz":-480},"id":"llP4SasBuXAN","outputId":"43ff74cc-68aa-4321-9848-d9fc0785a5af"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n","Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.19)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9270e743d5164397aee9d789cfec3552","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"988d23f9591d4bc4b8b0ca52626f29e6","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6dbe41eb88304205aa95ccf20d59e68c","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"777b6e9e2c46476c85452489d88325be","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["['the', 'patient', 'took', 'insulin', 'after', 'may', '6th']\n"]}],"source":["# Install the transformers library\n","!pip install transformers\n","\n","# Import the necessary modules\n","from transformers import BertTokenizer\n","\n","# Initialize the BERT tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","# Define the sentence to be tokenized\n","sentence = \"The patient took insulin after May 6th\"\n","\n","# Tokenize the sentence\n","tokens = tokenizer.tokenize(sentence)\n","\n","# Print the tokens\n","print(tokens)\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyML/Cs+MKDa5NFZYT9Gekqi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"10bf8340787e4900bf47e598d1249009":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"142970585c764b549b84fa6c8932fe09":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26b1e12b225942fbb5ff4de9010d0354":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e11c171dafda4021a28d04bb56e2b20b","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e72a62f7f30c40d0bc6494d002195fad","value":48}},"289c2df0c25b419c8a0a7f443644a5c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e1662c993234a6a8f49ef0775c1de56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e95635db0d6470c80ec6ea65d7d36e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a60025b14f64381957be1c217423fa4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db7aedf3e033448badef5441f44c7abc","placeholder":"​","style":"IPY_MODEL_664a67d58861483faf511c3c59debfff","value":" 48.0/48.0 [00:00&lt;00:00, 3.04kB/s]"}},"3b1021234da94ba9858d97ff156bf7ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e81923b77f3445919b91e6eef6f8655d","placeholder":"​","style":"IPY_MODEL_49a7b78653be4025a3ee72c529d667de","value":"vocab.txt: 100%"}},"46247476258e4a64bba9ed619dd67366":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49a7b78653be4025a3ee72c529d667de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b8361118c064d3d9e144e5536cae365":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a32f0c4f300d4e68a39086bc4101a256","placeholder":"​","style":"IPY_MODEL_bafbc18d6e9b4142bd29d9c8f862f7a0","value":" 466k/466k [00:00&lt;00:00, 24.1MB/s]"}},"5a93260155334b4c9dc8668a4a03f8c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb9c76e2981a462f82f3653036a6d806","placeholder":"​","style":"IPY_MODEL_5d606467ea8b49b8a4dfa033af378311","value":" 232k/232k [00:00&lt;00:00, 10.6MB/s]"}},"5d606467ea8b49b8a4dfa033af378311":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"664a67d58861483faf511c3c59debfff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66f636bc78634fde9a44111c9c23a623":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dbe41eb88304205aa95ccf20d59e68c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_822f539f794a4234805ffb2c94bd7cab","IPY_MODEL_c0528d0a8b3f4257b9234a5f2f4a9139","IPY_MODEL_4b8361118c064d3d9e144e5536cae365"],"layout":"IPY_MODEL_ece30b0166514288bebf78a3a974c94b"}},"777b6e9e2c46476c85452489d88325be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c26c22823241416985216d331da7bde4","IPY_MODEL_858f429a365d43a99d06b880c15f31cb","IPY_MODEL_e1afbd4c06cb468683016b2706f7aa33"],"layout":"IPY_MODEL_bcab38f43d2f49b0a7e87644fec743df"}},"7df4fff285194e94902a4768bd873383":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"822f539f794a4234805ffb2c94bd7cab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_142970585c764b549b84fa6c8932fe09","placeholder":"​","style":"IPY_MODEL_10bf8340787e4900bf47e598d1249009","value":"tokenizer.json: 100%"}},"83fbc39fb80a4018a38fb690c18f74a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"858f429a365d43a99d06b880c15f31cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a755705a6fe4aa681505b55a8579062","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bed9c2abe56e4b2994ebe9ce8ed97412","value":570}},"8a755705a6fe4aa681505b55a8579062":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9270e743d5164397aee9d789cfec3552":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c93cee2f61b345ff89805903935a529f","IPY_MODEL_26b1e12b225942fbb5ff4de9010d0354","IPY_MODEL_3a60025b14f64381957be1c217423fa4"],"layout":"IPY_MODEL_2e95635db0d6470c80ec6ea65d7d36e5"}},"970f149a42ff44a88ee4b3609eb546fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_66f636bc78634fde9a44111c9c23a623","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e1662c993234a6a8f49ef0775c1de56","value":231508}},"988d23f9591d4bc4b8b0ca52626f29e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b1021234da94ba9858d97ff156bf7ef","IPY_MODEL_970f149a42ff44a88ee4b3609eb546fc","IPY_MODEL_5a93260155334b4c9dc8668a4a03f8c6"],"layout":"IPY_MODEL_289c2df0c25b419c8a0a7f443644a5c4"}},"9ee3693423a14d079b0f662ab13fd6a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a32f0c4f300d4e68a39086bc4101a256":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6bc9e4e36d544349037e96dd5af7107":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a851e45549c242b39347fda5b1f0ea17":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3060e571dc841f9b4e0ccade2f24eb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bafbc18d6e9b4142bd29d9c8f862f7a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb9c76e2981a462f82f3653036a6d806":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcab38f43d2f49b0a7e87644fec743df":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bed9c2abe56e4b2994ebe9ce8ed97412":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c0528d0a8b3f4257b9234a5f2f4a9139":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ee3693423a14d079b0f662ab13fd6a5","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3060e571dc841f9b4e0ccade2f24eb3","value":466062}},"c26c22823241416985216d331da7bde4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46247476258e4a64bba9ed619dd67366","placeholder":"​","style":"IPY_MODEL_d0864335a7734977a12975b3ca937008","value":"config.json: 100%"}},"c93cee2f61b345ff89805903935a529f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83fbc39fb80a4018a38fb690c18f74a2","placeholder":"​","style":"IPY_MODEL_a6bc9e4e36d544349037e96dd5af7107","value":"tokenizer_config.json: 100%"}},"d0864335a7734977a12975b3ca937008":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db7aedf3e033448badef5441f44c7abc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e11c171dafda4021a28d04bb56e2b20b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1afbd4c06cb468683016b2706f7aa33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a851e45549c242b39347fda5b1f0ea17","placeholder":"​","style":"IPY_MODEL_7df4fff285194e94902a4768bd873383","value":" 570/570 [00:00&lt;00:00, 42.8kB/s]"}},"e72a62f7f30c40d0bc6494d002195fad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e81923b77f3445919b91e6eef6f8655d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ece30b0166514288bebf78a3a974c94b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"118d6aae7fc346e4a1736d6bc249b930":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b757b360627e4389a90e1b485bc61ac9","IPY_MODEL_cee12ab57f7041659be816f8cf2b8e71","IPY_MODEL_a261776c40f94be9b1d50d87fbb67b79"],"layout":"IPY_MODEL_706f9274d5d24e739877f4122f1423f8"}},"b757b360627e4389a90e1b485bc61ac9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a68b0a635c44624a959067d449ef1cb","placeholder":"​","style":"IPY_MODEL_7b72cb404bb2475b904ee029efb884c6","value":"tokenizer_config.json: 100%"}},"cee12ab57f7041659be816f8cf2b8e71":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae0efe1a3494495a82d6aa320055477e","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc563fd586df403aa1bbdbe2fac8e8d0","value":48}},"a261776c40f94be9b1d50d87fbb67b79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e55aa611423542929e96ea6e3373fcbf","placeholder":"​","style":"IPY_MODEL_b6e09dce0e0b47679a49c0fb8d9fa4f2","value":" 48.0/48.0 [00:00&lt;00:00, 3.17kB/s]"}},"706f9274d5d24e739877f4122f1423f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a68b0a635c44624a959067d449ef1cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b72cb404bb2475b904ee029efb884c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae0efe1a3494495a82d6aa320055477e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc563fd586df403aa1bbdbe2fac8e8d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e55aa611423542929e96ea6e3373fcbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6e09dce0e0b47679a49c0fb8d9fa4f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c48a79e3219a4b7aaee5f4779d5cdd20":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_873efed9f48f44059687ddab8c7b68b5","IPY_MODEL_28a27ea38f9246d59f6fa1ad6427df52","IPY_MODEL_9a6d19178c1443c495c39c5552e044bd"],"layout":"IPY_MODEL_218747659d7140b3ae0b79a4c33d1913"}},"873efed9f48f44059687ddab8c7b68b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70e818db46f54cdcabc7cee7fb800ff3","placeholder":"​","style":"IPY_MODEL_20af1155376d463286f4c80fdc9fb3e6","value":"vocab.txt: 100%"}},"28a27ea38f9246d59f6fa1ad6427df52":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7baa4fa724d458bb5540c8382fa9b0b","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_54d27c01a6df4ee3812fd208cb798f76","value":231508}},"9a6d19178c1443c495c39c5552e044bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c825b8faec6e4aca84d2f9db9df80218","placeholder":"​","style":"IPY_MODEL_d29bddf100b34e5d84af777da6fc3882","value":" 232k/232k [00:00&lt;00:00, 1.38MB/s]"}},"218747659d7140b3ae0b79a4c33d1913":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70e818db46f54cdcabc7cee7fb800ff3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"20af1155376d463286f4c80fdc9fb3e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7baa4fa724d458bb5540c8382fa9b0b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54d27c01a6df4ee3812fd208cb798f76":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c825b8faec6e4aca84d2f9db9df80218":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d29bddf100b34e5d84af777da6fc3882":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30df7fef73944e8eb28b199cb56408f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9485bc7869c5464089490638de80491c","IPY_MODEL_139d2e3407f74834938e9d659d33da9a","IPY_MODEL_be53917e12b0402590e1940e74a11954"],"layout":"IPY_MODEL_d5c005ab5a02485297ae07238ac1c09a"}},"9485bc7869c5464089490638de80491c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_550c9110efec4803b69d0b0d720e731a","placeholder":"​","style":"IPY_MODEL_b2f6565da1ac4e4bb86d6ce82ac4ff4d","value":"tokenizer.json: 100%"}},"139d2e3407f74834938e9d659d33da9a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25922cfb99f04a5e970fc93e0f0b2f09","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c190b1d6ebb04dc5ad9abc5a3bcc65d9","value":466062}},"be53917e12b0402590e1940e74a11954":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0553068fd8734f73819165a22972ccab","placeholder":"​","style":"IPY_MODEL_2b593fb72c4642d581205bb8a88fafdc","value":" 466k/466k [00:00&lt;00:00, 1.98MB/s]"}},"d5c005ab5a02485297ae07238ac1c09a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"550c9110efec4803b69d0b0d720e731a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2f6565da1ac4e4bb86d6ce82ac4ff4d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25922cfb99f04a5e970fc93e0f0b2f09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c190b1d6ebb04dc5ad9abc5a3bcc65d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0553068fd8734f73819165a22972ccab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b593fb72c4642d581205bb8a88fafdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0422c7dbdf534ba7ba31dc4357df290e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e36c4a9d1f544948a6f76278ac8e05e5","IPY_MODEL_834125b4fa594c479551a2b1d6845383","IPY_MODEL_d96ceea82ea34d9394aa4f9d58c46651"],"layout":"IPY_MODEL_f80fcb022d92454fb865138d67b3c79b"}},"e36c4a9d1f544948a6f76278ac8e05e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_901e1b03f85a4fc4b73a9476ab22a1a5","placeholder":"​","style":"IPY_MODEL_6261eea7475c4b41add98bd634504663","value":"config.json: 100%"}},"834125b4fa594c479551a2b1d6845383":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9774ee37643f4ba18eb4ba942c9d8137","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c46d75636073439f813c9f491983db98","value":570}},"d96ceea82ea34d9394aa4f9d58c46651":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7013f6bfc731463e8b3ba0d3f6d46bf2","placeholder":"​","style":"IPY_MODEL_c2d79344680e4c9ba87e3ce7d54b1469","value":" 570/570 [00:00&lt;00:00, 8.86kB/s]"}},"f80fcb022d92454fb865138d67b3c79b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"901e1b03f85a4fc4b73a9476ab22a1a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6261eea7475c4b41add98bd634504663":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9774ee37643f4ba18eb4ba942c9d8137":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c46d75636073439f813c9f491983db98":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7013f6bfc731463e8b3ba0d3f6d46bf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2d79344680e4c9ba87e3ce7d54b1469":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3fa577bd73c495db71b22eb2a2fa1d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3119789429ca4c30bd1a9b8325d5ef3f","IPY_MODEL_deead8607ac64a5bb9df8f47bde496c3","IPY_MODEL_6a112f744b16417785ed773e5767f162"],"layout":"IPY_MODEL_37996f3c3ad244d79a049f3bf5114d18"}},"3119789429ca4c30bd1a9b8325d5ef3f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68dfd9d8aba04388b3b5b23c9bb4481c","placeholder":"​","style":"IPY_MODEL_b5dc1b4e12c647e78f7b96afa15a9b26","value":"model.safetensors: 100%"}},"deead8607ac64a5bb9df8f47bde496c3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17a1dfe6b93a4281af14a0fc45ca3238","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_912c8056b7d34771869ea8d1bb211dde","value":440449768}},"6a112f744b16417785ed773e5767f162":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99f649797ec34390947a8f4a862647d7","placeholder":"​","style":"IPY_MODEL_97143fb56ade4b67820f8a010e4fb654","value":" 440M/440M [00:01&lt;00:00, 303MB/s]"}},"37996f3c3ad244d79a049f3bf5114d18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68dfd9d8aba04388b3b5b23c9bb4481c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5dc1b4e12c647e78f7b96afa15a9b26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17a1dfe6b93a4281af14a0fc45ca3238":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"912c8056b7d34771869ea8d1bb211dde":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"99f649797ec34390947a8f4a862647d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97143fb56ade4b67820f8a010e4fb654":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55d71e8b8502480c8eb7fb1d9ef56753":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_788d7a29589744be905b2d1b24a31e74","IPY_MODEL_aaefaac4bc264bc2899720eafec85068","IPY_MODEL_6712b469ff6f46189d305dbf5c3a5e5d"],"layout":"IPY_MODEL_5d532571a77a4d378eb861f911456e92"}},"788d7a29589744be905b2d1b24a31e74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_744594703bce462aae04ea8159f6f442","placeholder":"​","style":"IPY_MODEL_8a16f2bec7d34d1aa019fc99ba049fc8","value":"model.safetensors: 100%"}},"aaefaac4bc264bc2899720eafec85068":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_644c2c406a0c444d929ba07ba9fd602e","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a957393afeb74fa48c390cd703801a4f","value":440449768}},"6712b469ff6f46189d305dbf5c3a5e5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1232ec83abe4c11963c2bd99e6712e9","placeholder":"​","style":"IPY_MODEL_8cf54394449841aeb26c8b26dabc7a74","value":" 440M/440M [00:01&lt;00:00, 294MB/s]"}},"5d532571a77a4d378eb861f911456e92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"744594703bce462aae04ea8159f6f442":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a16f2bec7d34d1aa019fc99ba049fc8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"644c2c406a0c444d929ba07ba9fd602e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a957393afeb74fa48c390cd703801a4f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f1232ec83abe4c11963c2bd99e6712e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cf54394449841aeb26c8b26dabc7a74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}